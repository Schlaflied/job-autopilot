# Job Autopilot - Resume Export ä¼˜åŒ–å®æ–½è®¡åˆ’

åŸºäº `RESUME_EXPORT_IMPLEMENTATION.md` æ–‡æ¡£åˆ†æï¼Œä¸ºé¡¹ç›®æ·»åŠ å®Œæ•´çš„ Resume Export åŠŸèƒ½ï¼Œå¹¶ä¼˜åŒ–ç°æœ‰ä»£ç åº“ã€‚

---

## ğŸ“Š å®æ–½æ‘˜è¦

### ğŸ¯ æœ¬æ¬¡ä¼˜åŒ–èŒƒå›´

æœ¬æ¬¡å®æ–½å°†ä¸º Job Autopilot æ·»åŠ å®Œæ•´çš„ **Resume Export** åŠŸèƒ½ï¼ŒåŒ…æ‹¬å‰ç«¯ UIã€åç«¯é€»è¾‘ã€æ•°æ®åº“ Schemaã€ä¾èµ–ç®¡ç†å’Œæµ‹è¯•éªŒè¯ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- âœ… 4 ç§ä¸“ä¸šç®€å†æ¨¡æ¿ï¼ˆClassic/Modern Ã— Single/Two Columnï¼‰
- âœ… AI æ™ºèƒ½å‹ç¼©ï¼ˆå°† Master Resume å‹ç¼©åˆ° 1 é¡µï¼‰
- âœ… å¤šæ ¼å¼æ”¯æŒï¼ˆMD/PDF/DOCX è¾“å…¥ï¼‰
- âœ… äº¤äº’å¼ç¼–è¾‘ï¼ˆSection é‡æ’ã€è¡Œé—´è·è°ƒæ•´ï¼‰
- âœ… ç‰ˆæœ¬å†å²è¿½è¸ª
- âœ… ATS Score åŠŸèƒ½ï¼ˆåŸºäº Resume-Matcherï¼‰
- âœ… Streamlit UI ç¾åŒ–

---

### â±ï¸ ç”¨æ—¶ä¼°ç®—

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡ç”¨æ—¶ | ç´¯è®¡ç”¨æ—¶ |
|------|------|----------|----------|
| **Phase 1: Foundation** | åˆ›å»ºæ¨¡æ¿æ–‡ä»¶ã€å®‰è£…ä¾èµ–ã€æ•°æ®åº“è¿ç§» | 30 åˆ†é’Ÿ | 0.5h |
| **Phase 2: Backend** | å®ç°åç«¯é€»è¾‘ï¼ˆæ¨¡æ¿ç³»ç»Ÿã€PDF/DOCXè§£æã€AIå‹ç¼©ï¼‰ | 1.5 å°æ—¶ | 2h |
| **Phase 3: Frontend** | å®ç°å‰ç«¯ UIï¼ˆResume Export é¡µé¢ã€äº¤äº’ç»„ä»¶ï¼‰ | 2 å°æ—¶ | 4h |
| **Phase 4: Testing** | æµ‹è¯•éªŒè¯ï¼ˆä¾èµ–ã€æ¨¡æ¿ã€è§£æã€ATSï¼‰ | 30 åˆ†é’Ÿ | 4.5h |
| **Phase 5: UI Polish** | Streamlit UI ç¾åŒ–ï¼ˆå¯é€‰ï¼‰ | 30 åˆ†é’Ÿ | 5h |
| **æ€»è®¡** |  | **5 å°æ—¶** | |

---

### ğŸ†• æ–°å¢åŠŸèƒ½åˆ—è¡¨

#### **1. ç®€å†å¯¼å‡ºç³»ç»Ÿ**
- **4 ä¸ªä¸“ä¸šæ¨¡æ¿**ï¼šClassic Single, Modern Single, Classic Two-Column, Modern Two-Column
- **æ¨¡æ¿é¢„è§ˆ**ï¼š600x800px é«˜æ¸…é¢„è§ˆå›¾ï¼ˆç‚¹å‡»æ”¾å¤§ï¼‰
- **æ¨¡æ¿é…ç½®**ï¼šJSON æ ¼å¼ï¼ˆå­—ä½“ã€é¢œè‰²ã€é—´è·ã€å¸ƒå±€ï¼‰

#### **2. Master Resume è§£æå™¨**
- **MD è§£æ**ï¼šMarkdown æ ¼å¼ç®€å†è§£æï¼ˆç°æœ‰åŠŸèƒ½ï¼‰
- **PDF è§£æ**ï¼šPyPDF2 æ–‡æœ¬æå– + AI ç»“æ„åŒ–
- **DOCX è§£æ**ï¼špython-docx å†…å®¹æå– + AI ç»“æ„åŒ–
- **OCR æ”¯æŒ**ï¼ˆå¯é€‰ï¼‰ï¼špdf2image + pytesseractï¼ˆæ‰«æç‰ˆ PDFï¼‰

#### **3. AI æ™ºèƒ½å‹ç¼©**
- **3 ç§å‹ç¼©ç­–ç•¥**ï¼šAggressiveï¼ˆ80% å‹ç¼©ï¼‰ã€Balancedï¼ˆ70%ï¼‰ã€Conservativeï¼ˆ60%ï¼‰
- **åŠ¨æ€å­—æ•°é™åˆ¶**ï¼šSingle-column (600 words) vs Two-column (700 words)
- **å…³é”®è¯ä¿ç•™**ï¼šç¡®ä¿ JD å…³é”®è¯ä¸è¢«åˆ é™¤
- **1 é¡µçº¦æŸ**ï¼š95%+ ç®€å†å‹ç¼©åˆ° 1 é¡µ

#### **4. äº¤äº’å¼ç¼–è¾‘å™¨**
- **Section é‡æ’**ï¼šDrag-dropï¼ˆstreamlit-sortablesï¼‰+ ç®­å¤´æŒ‰é’®ï¼ˆç§»åŠ¨ç«¯å‹å¥½ï¼‰
- **è¡Œé—´è·è°ƒæ•´**ï¼šSlider (0.8-1.5)ï¼Œå®æ—¶é¢„è§ˆå­—æ•°
- **Inline ç¼–è¾‘**ï¼šSummary, Experience åœ¨çº¿ç¼–è¾‘
- **å­—æ•°ç»Ÿè®¡**ï¼šå®æ—¶æ˜¾ç¤ºå½“å‰å­—æ•°å’Œ 1 é¡µé¢„ä¼°

#### **5. ç‰ˆæœ¬å†å²ç®¡ç†**
- **è‡ªåŠ¨ä¿å­˜**ï¼šæ¯æ¬¡å¯¼å‡ºä¿å­˜åˆ°æ•°æ®åº“ï¼ˆ`resume_versions` è¡¨ï¼‰
- **ç‰ˆæœ¬åˆ—è¡¨**ï¼šæŸ¥çœ‹æ‰€æœ‰å†å²ç‰ˆæœ¬ï¼ˆæ—¶é—´ã€æ¨¡æ¿ã€Jobï¼‰
- **é‡æ–°å¯¼å‡º**ï¼šä»å†å²ç‰ˆæœ¬é‡æ–°ç”Ÿæˆ DOCX/PDF
- **è‡ªåŠ¨æ¸…ç†**ï¼š90 å¤©åè‡ªåŠ¨åˆ é™¤ï¼ˆPrivacy åˆè§„ï¼‰

#### **6. ATS Score åŠŸèƒ½**ï¼ˆåŸºäº Resume-Matcherï¼‰
- **åŒ¹é…åº¦è¯„åˆ†**ï¼š0-100 åˆ†ï¼ˆResume vs Job Descriptionï¼‰
- **å…³é”®è¯åˆ†æ**ï¼šæå–ç¼ºå¤±çš„å…³é”®è¯ï¼ˆTop 10ï¼‰
- **æ”¹è¿›å»ºè®®**ï¼šAI ç”Ÿæˆä¼˜åŒ–å»ºè®®
- **ç¼“å­˜æœºåˆ¶**ï¼šç›¸åŒ Resume + JD é¿å…é‡å¤è®¡ç®—

#### **7. Streamlit UI ç¾åŒ–**
- **Custom CSS**ï¼šæ¸å˜èƒŒæ™¯ã€å¡ç‰‡é˜´å½±ã€Hover æ•ˆæœ
- **ä¸“ä¸šèœå•**ï¼šstreamlit-option-menu ä¾§è¾¹æ 
- **åŠ¨ç”» Loading**ï¼šstreamlit-lottie åŠ¨ç”»æ•ˆæœ
- **Metric Cards**ï¼šstreamlit-extras ç¾åŒ–æŒ‡æ ‡å¡ç‰‡
- **Progress Indicator**ï¼šæ­¥éª¤å¯¼èˆªï¼ˆUpload â†’ Template â†’ Customize â†’ Exportï¼‰

---

### ğŸ—ï¸ å‰ç«¯ä¼˜åŒ–é€»è¾‘

#### **æ–°å¢é¡µé¢ï¼šResume Export**

**é¡µé¢è·¯ç”±**ï¼š
```
ğŸ“„ Resume Export
â”œâ”€â”€ Step 1: Upload Master Resume (æ–‡ä»¶ä¸Šä¼ )
â”œâ”€â”€ Step 2: Select Job (å¯é€‰ï¼Œä»ç¼“å­˜ jobs é€‰æ‹©)
â”œâ”€â”€ Step 3: Choose Template (æ¨¡æ¿é€‰æ‹©å™¨ï¼Œ4 å¼ å¡ç‰‡)
â”œâ”€â”€ Step 4: Customize Resume
â”‚   â”œâ”€â”€ Section Reordering (æ‹–æ‹½æˆ–ç®­å¤´)
â”‚   â”œâ”€â”€ Line Spacing Slider (0.8-1.5)
â”‚   â”œâ”€â”€ Inline Editors (Summary, Experience)
â”‚   â””â”€â”€ Word Count Preview (å®æ—¶)
â”œâ”€â”€ Step 5: AI Compression (3 ä¸ªé€‰é¡¹)
â”œâ”€â”€ Step 6: ATS Score (åŒ¹é…åº¦åˆ†æ)
â””â”€â”€ Step 7: Export & Version History
    â”œâ”€â”€ Download DOCX
    â”œâ”€â”€ Download PDF
    â””â”€â”€ View History
```

#### **UI ç»„ä»¶ä¼˜åŒ–**

**1. Template Selector**
```python
# 4 å¼ é«˜æ¸…é¢„è§ˆå›¾ï¼ˆ600x800pxï¼‰
from streamlit_card import card

cols = st.columns(4)
for i, template in enumerate(templates):
    with cols[i]:
        card(
            title=template["name"],
            text=template["desc"],
            image=f"assets/templates/{template['img']}",
            styles={"card": {"border-radius": "10px", "box-shadow": "0 4px 6px rgba(0,0,0,0.1)"}}
        )
```

**2. Section Reordering**ï¼ˆåŒæ¨¡å¼ï¼‰
```python
# Method 1: Drag-drop (Desktop)
from streamlit_sortables import sort_items
reordered = sort_items(sections, key="order")

# Method 2: Arrow buttons (Mobile fallback)
for i, section in enumerate(sections):
    col1, col2, col3 = st.columns([3, 1, 1])
    col1.write(section)
    if i > 0:
        col2.button("â¬†ï¸", key=f"up_{section}")
    if i < len(sections) - 1:
        col3.button("â¬‡ï¸", key=f"down_{section}")
```

**3. AI Compression Options**
```python
compression_mode = st.radio(
    "AI Compression Strategy",
    ["Aggressive (80%)", "Balanced (70%)", "Conservative (60%)"],
    help="How much to compress your resume"
)

with st.spinner("ğŸ¤– AI is tailoring your resume..."):
    progress_bar = st.progress(0)
    compressed_versions = []
    for i in range(3):
        version = ai_compress(mode=modes[i])
        compressed_versions.append(version)
        progress_bar.progress((i+1) / 3)
```

**4. ATS Score Display**
```python
ats_score = ats_scorer.score_resume(resume_text, job_description)

st.metric("ATS Match Score", f"{ats_score['score']}/100", 
          delta="+15 vs raw resume")

with st.expander("ğŸ“Š Missing Keywords"):
    st.write(", ".join(ats_score['missing_keywords']))

with st.expander("ğŸ’¡ Suggestions"):
    for suggestion in ats_score['suggestions']:
        st.markdown(f"- {suggestion}")
```

---

### ğŸ”§ åç«¯ä¼˜åŒ–é€»è¾‘

#### **æ–°å¢/ä¿®æ”¹çš„åç«¯æ¨¡å—**

**1. Template System** (`modules/resume_generator.py`)

```python
class ResumeGenerator:
    def load_template(self, template_name: str) -> Dict:
        """Load template JSON configuration"""
        template_path = f"data/templates/{template_name}.json"
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def apply_template(self, resume_data: Dict, template: Dict) -> Dict:
        """Apply template settings to resume data"""
        # Reorder sections based on template
        ordered_resume = {}
        for section in template['section_order']:
            if section in resume_data:
                ordered_resume[section] = resume_data[section]
        
        # Apply line spacing, fonts, margins
        ordered_resume['_meta'] = {
            'line_spacing': template['line_spacing'],
            'fonts': template['fonts'],
            'margins': template['margins']
        }
        
        return ordered_resume
```

**2. Multi-Format Parser**

```python
def parse_pdf_resume(self, pdf_path: str) -> Dict:
    """Parse PDF using PyPDF2 + AI structuring"""
    import PyPDF2
    
    # Extract text
    with open(pdf_path, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        text = "".join([page.extract_text() for page in reader.pages])
    
    # If text too short, try OCR
    if len(text) < 100:
        text = self._extract_with_ocr(pdf_path)  # pdf2image + pytesseract
    
    # AI structuring
    prompt = f"Parse this resume into JSON with keys: name, contact, summary, experience, education, skills\n\n{text[:2000]}"
    response = ai_agent.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return json.loads(response.choices[0].message.content)

def parse_docx_resume(self, docx_path: str) -> Dict:
    """Parse DOCX using python-docx + AI"""
    from docx import Document
    
    doc = Document(docx_path)
    text = "\n".join([para.text for para in doc.paragraphs])
    
    # Same AI structuring as PDF
    return self._parse_with_ai(text)
```

**3. AI Compression Engine**

```python
def compress_to_one_page(self, resume_data: Dict, template: Dict, 
                        job_description: str, mode: str = "balanced") -> Dict:
    """Compress resume to fit 1 page using AI"""
    
    # Calculate word limit based on template
    if template.get('layout') == 'two_column':
        word_limit = 700
    else:
        word_limit = 600
    
    # Adjust based on line spacing
    line_spacing = template.get('line_spacing', 1.0)
    if line_spacing < 1.0:
        word_limit += 50
    
    # Compression strategies
    compression_ratios = {
        "aggressive": 0.80,  # 80% compression
        "balanced": 0.70,
        "conservative": 0.60
    }
    
    target_words = int(word_limit * (1 - compression_ratios[mode]))
    
    # AI prompt
    prompt = f"""Compress this resume to {target_words} words while keeping relevance to this job:
    
Job Description: {job_description[:500]}

Resume: {json.dumps(resume_data, indent=2)}

Requirements:
1. Keep ALL keywords from job description
2. Prioritize recent experience
3. Remove redundant bullets
4. Quantify achievements
5. Return JSON format (same structure as input)
"""
    
    response = ai_agent.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": "You are an expert resume optimizer."},
                  {"role": "user", "content": prompt}],
        temperature=0.5
    )
    
    compressed = json.loads(response.choices[0].message.content)
    compressed[' _word_count'] = self._count_words(compressed)
    
    return compressed
```

**4. ATS Scorer** (`modules/ats_scorer.py` - NEW)

```python
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import spacy

class ATSScorer:
    """ATS compatibility scorer inspired by Resume-Matcher"""
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        self.vectorizer = TfidfVectorizer()
        self.cache = {}  # Simple in-memory cache
    
    def score_resume(self, resume_text: str, job_description: str) -> Dict:
        """Calculate ATS match score (0-100)"""
        
        # Check cache
        cache_key = hashlib.md5(f"{resume_text[:100]}_{job_description[:100]}".encode()).hexdigest()
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # Vectorize and calculate similarity
        vectors = self.vectorizer.fit_transform([resume_text, job_description])
        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]
        
        # Extract keywords
        jd_keywords = self._extract_keywords(job_description)
        resume_keywords = self._extract_keywords(resume_text)
        missing = set(jd_keywords) - set(resume_keywords)
        
        result = {
            "score": int(similarity * 100),
            "missing_keywords": list(missing)[:10],
            "suggestions": self._generate_suggestions(missing)
        }
        
        # Cache result
        self.cache[cache_key] = result
        return result
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extract important keywords using spaCy NLP"""
        doc = self.nlp(text)
        keywords = [token.text.lower() for token in doc 
                   if token.pos_ in ["NOUN", "PROPN"] and not token.is_stop]
        return list(set(keywords))
    
    def _generate_suggestions(self, missing_keywords: set) -> List[str]:
        """Generate improvement suggestions based on missing keywords"""
        suggestions = []
        for keyword in list(missing_keywords)[:5]:
            suggestions.append(f"Consider adding '{keyword}' to your resume")
        return suggestions
```

**5. Version History** (`modules/database.py`)

```python
# New table
class ResumeVersion(Base):
    __tablename__ = 'resume_versions'
    
    id = Column(Integer, primary_key=True)
    job_id = Column(Integer, ForeignKey('jobs.id'))
    template_name = Column(String(50))
    resume_data = Column(JSON)  # Full resume JSON
    compression_mode = Column(String(20))  # aggressive/balanced/conservative
    ats_score = Column(Integer)  # 0-100
    created_at = Column(DateTime, default=datetime.utcnow)
    file_path_docx = Column(String(255))
    file_path_pdf = Column(String(255))
    
    # Privacy compliance
    user_consent = Column(Boolean, default=False)
    retention_days = Column(Integer, default=90)

# Methods
def save_version(self, resume_data: Dict, job_id: int, template: str, 
                ats_score: int) -> int:
    """Save resume version to database"""
    version = ResumeVersion(
        job_id=job_id,
        template_name=template,
        resume_data=resume_data,
        ats_score=ats_score,
        user_consent=True  # From UI checkbox
    )
    db.session.add(version)
    db.session.commit()
    return version.id

def get_version_history(self, job_id: int = None) -> List[ResumeVersion]:
    """Get all resume versions"""
    query = db.session.query(ResumeVersion)
    if job_id:
        query = query.filter_by(job_id=job_id)
    return query.order_by(ResumeVersion.created_at.desc()).all()
```

---

**6. æ•°æ®åº“é…ç½®çµæ´»æ€§**ï¼ˆæ”¯æŒæœ¬åœ° + äº‘ç«¯ï¼‰

**èƒŒæ™¯**ï¼šä½ å½“å‰ç”¨äº‘ç«¯ Neon PostgreSQLï¼Œä½†ç”¨æˆ·è‡ªå·±éƒ¨ç½²å¯èƒ½ç”¨æœ¬åœ° SQLiteã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡ç¯å¢ƒå˜é‡ `DATABASE_URL` è‡ªåŠ¨åˆ‡æ¢æ•°æ®åº“ã€‚

**ä¿®æ”¹æ–‡ä»¶**ï¼š`modules/database.py`

```python
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

load_dotenv()

# Auto-detect database type
DATABASE_URL = os.getenv("DATABASE_URL")

if not DATABASE_URL:
    # Fallback to local SQLite if no URL provided
    DATABASE_URL = "sqlite:///data/job_autopilot.db"
    print("âš ï¸ No DATABASE_URL found, using local SQLite")

# Create engine (works for SQLite, PostgreSQL, MySQL, etc.)
engine = create_engine(
    DATABASE_URL,
    echo=False,  # Set to True for SQL debugging
    pool_pre_ping=True  # Check connection health
)

SessionLocal = sessionmaker(bind=engine)

# Create all tables
Base.metadata.create_all(bind=engine)

print(f"âœ… Database connected: {DATABASE_URL.split('@')[0]}...")  # Don't print password
```

**ç¯å¢ƒå˜é‡é…ç½®**ï¼ˆ`.env`ï¼‰ï¼š

```bash
# .env.example

# ============================================================
# Database Configuration
# ============================================================

# Option 1: Cloud PostgreSQL (Neon, Supabase, etc.)
DATABASE_URL=postgresql://user:password@ep-cool-cloud-12345.us-east-2.aws.neon.tech/job_autopilot

# Option 2: Local PostgreSQL
# DATABASE_URL=postgresql://localhost/job_autopilot

# Option 3: Local SQLite (Default, no setup needed)
# DATABASE_URL=sqlite:///data/job_autopilot.db

# ============================================================
# Storage Mode (for resume files)
# ============================================================

# Where to save resume DOCX/PDF files
STORAGE_MODE=local  # or 'cloud' (AWS S3, Cloudflare R2, etc.)

# If STORAGE_MODE=cloud, configure cloud storage
# AWS_ACCESS_KEY_ID=your_key
# AWS_SECRET_ACCESS_KEY=your_secret
# AWS_S3_BUCKET=job-autopilot-resumes
# AWS_REGION=us-east-1
```

**ä¸ºç”¨æˆ·æä¾›çš„æ–‡æ¡£**ï¼ˆ`README.md`ï¼‰ï¼š

```markdown
## ğŸ—„ï¸ Database Setup

Job Autopilot supports **local** and **cloud** database deployments:

### Option 1: Local SQLite (Easiest, No Setup)

Perfect for personal use or testing.

```bash
# No configuration needed! Just run:
streamlit run streamlit_app.py

# Database will be created at: data/job_autopilot.db
```

### Option 2: Cloud PostgreSQL (Recommended for Production)

Use **Neon**, **Supabase**, or any PostgreSQL provider.

```bash
# 1. Get your database URL from provider
# 2. Add to .env:
DATABASE_URL=postgresql://user:password@host.neon.tech/dbname

# 3. Run migrations:
python scripts/init_database.py

# 4. Start app:
streamlit run streamlit_app.py
```

### Option 3: Local PostgreSQL

```bash
# 1. Install PostgreSQL locally
# 2. Create database:
createdb job_autopilot

# 3. Add to .env:
DATABASE_URL=postgresql://localhost/job_autopilot

# 4. Run migrations and start app
```

### Resume File Storage

Resume files (DOCX/PDF) can be stored:

- **Locally**: `data/resumes/` (Default)
- **Cloud**: AWS S3, Cloudflare R2 (Set `STORAGE_MODE=cloud` in `.env`)

For cloud storage, see [Cloud Storage Setup Guide](docs/cloud-storage.md).
```

**Docker æ”¯æŒ**ï¼ˆ`docker-compose.yml`ï¼‰ï¼š

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8501:8501"
    environment:
      # Use cloud database
      - DATABASE_URL=${DATABASE_URL}
      # Or use bundled PostgreSQL (see below)
      # - DATABASE_URL=postgresql://postgres:password@db:5432/job_autopilot
    volumes:
      - ./data:/app/data  # For local SQLite or file storage
  
  # Optional: Local PostgreSQL container
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: job_autopilot
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

**ä½¿ç”¨åœºæ™¯å¯¹æ¯”**ï¼š

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | DATABASE_URL | ä¼˜ç‚¹ |
|------|----------|-------------|------|
| **ä¸ªäººå¼€å‘/æµ‹è¯•** | SQLite | `sqlite:///data/job_autopilot.db` | é›¶é…ç½®ï¼Œå³å¼€å³ç”¨ |
| **ä½ è‡ªå·±ä½¿ç”¨** | Neon PostgreSQL | `postgresql://...neon.tech/...` | äº‘ç«¯å¤‡ä»½ï¼Œå¤šè®¾å¤‡åŒæ­¥ |
| **ç”¨æˆ·è‡ªå·±éƒ¨ç½²** | SQLite | `sqlite:///data/job_autopilot.db` | ç®€å•ï¼Œæ— éœ€æ•°æ®åº“æœåŠ¡ |
| **ä¼ä¸šéƒ¨ç½²** | æœ¬åœ°/äº‘ç«¯ PostgreSQL | æ ¹æ®éœ€æ±‚ | é«˜æ€§èƒ½ï¼Œæ”¯æŒå¹¶å‘ |
| **Docker éƒ¨ç½²** | Docker PostgreSQL | `postgresql://db:5432/...` | å®¹å™¨åŒ–ï¼Œæ˜“è¿ç§» |

**è‡ªåŠ¨æ£€æµ‹é€»è¾‘**ï¼ˆç”¨æˆ·å‹å¥½ï¼‰ï¼š

```python
# modules/database.py
def get_database_info():
    """Get human-readable database info"""
    db_url = os.getenv("DATABASE_URL", "sqlite:///data/job_autopilot.db")
    
    if db_url.startswith("sqlite"):
        return {
            "type": "SQLite",
            "location": "Local",
            "file": db_url.replace("sqlite:///", ""),
            "suitable_for": "Personal use, testing"
        }
    elif db_url.startswith("postgresql"):
        host = db_url.split("@")[1].split("/")[0]
        if "neon" in host or "supabase" in host:
            return {
                "type": "PostgreSQL",
                "location": "Cloud",
                "provider": "Neon/Supabase",
                "suitable_for": "Production, multi-device"
            }
        else:
            return {
                "type": "PostgreSQL",
                "location": "Local/Self-hosted",
                "suitable_for": "Production, high performance"
            }
```

**åœ¨ Streamlit UI æ˜¾ç¤º**ï¼ˆ`streamlit_app.py` - Settings é¡µé¢ï¼‰ï¼š

```python
# In Settings page
st.markdown("### ğŸ—„ï¸ Database Configuration")

db_info = get_database_info()

st.info(f"""
**Database Type**: {db_info['type']}  
**Location**: {db_info['location']}  
**Suitable For**: {db_info['suitable_for']}
""")

if db_info['type'] == 'SQLite':
    st.success("âœ… Using local SQLite - No setup needed!")
    st.caption(f"ğŸ“‚ Database file: `{db_info['file']}`")
else:
    st.success("âœ… Using PostgreSQL - Cloud/Production ready")
    
# Provide migration guide
with st.expander("ğŸ“– How to change database"):
    st.markdown("""
    1. Edit `.env` file:
       ```
       DATABASE_URL=<your-database-url>
       ```
    2. Run migration:
       ```bash
       python scripts/init_database.py
       ```
    3. Restart Streamlit
    """)
```

---

### ğŸ“¦ æ–‡ä»¶å˜æ›´æ¸…å•

**æ–°å¢ 11 ä¸ªæ–‡ä»¶**ï¼š
1. `data/templates/classic_single_column.json`
2. `data/templates/modern_single_column.json`
3. `data/templates/classic_two_column.json`
4. `data/templates/modern_two_column.json`
5. `assets/templates/classic_single.jpg` (600x800px)
6. `assets/templates/modern_single.jpg` (600x800px)
7. `assets/templates/classic_two.jpg` (600x800px)
8. `assets/templates/modern_two.jpg` (600x800px)
9. `scripts/generate_template_previews.py`
10. `modules/ats_scorer.py`
11. `scripts/test_dependencies.py`

**ä¿®æ”¹ 7 ä¸ªæ–‡ä»¶**ï¼š
1. `streamlit_app.py` (+300 lines - æ–°å¢ Resume Export é¡µé¢)
2. `modules/resume_generator.py` (+200 lines - æ¨¡æ¿ç³»ç»Ÿã€è§£æå™¨ã€å‹ç¼©)
3. `modules/database.py` (+50 lines - `ResumeVersion` æ¨¡å‹)
4. `requirements.txt` (+8 dependencies)
5. `scripts/init_database.py` (migration script)
6. `README.md` (è‡´è°¢ Resume-Matcher)
7. `.gitignore` (å¿½ç•¥ç”Ÿæˆçš„ç®€å†æ–‡ä»¶)

---

### ğŸ§ª æµ‹è¯•éªŒè¯è®¡åˆ’

**Automated Tests**ï¼š
- âœ… ä¾èµ–å®‰è£…æµ‹è¯•ï¼ˆ`test_dependencies.py`ï¼‰
- âœ… æ¨¡æ¿åŠ è½½æµ‹è¯•ï¼ˆ4 ä¸ª JSON éƒ½èƒ½æ­£ç¡®åŠ è½½ï¼‰
- âœ… PDF/DOCX è§£ææµ‹è¯•ï¼ˆå‡†å¤‡æµ‹è¯•æ–‡ä»¶ï¼‰
- âœ… AI å‹ç¼©æµ‹è¯•ï¼ˆ3 ç§æ¨¡å¼éƒ½ç”Ÿæˆ â‰¤600 wordsï¼‰
- âœ… ATS Score æµ‹è¯•ï¼ˆResume-Matcher æµ‹è¯•æ•°æ®ï¼‰

**Manual Verification**ï¼š
- âœ… Upload MD/PDF/DOCX éƒ½èƒ½æ­£ç¡®è§£æ
- âœ… 4 ä¸ªæ¨¡æ¿é¢„è§ˆå›¾éƒ½èƒ½æ˜¾ç¤º
- âœ… Drag-drop å’Œç®­å¤´æŒ‰é’®éƒ½èƒ½ç”¨
- âœ… Line spacing å½±å“å­—æ•°ä¼°ç®—
- âœ… AI å‹ç¼©ç”Ÿæˆ 3 ä¸ªé€‰é¡¹
- âœ… DOCX/PDF å¯¼å‡ºæˆåŠŸä¸‹è½½
- âœ… Version history æ­£ç¡®ä¿å­˜å’Œè¯»å–
- âœ… ATS Score æ˜¾ç¤ºæ­£ç¡®ï¼ˆåŒ¹é…åº¦ + å…³é”®è¯ï¼‰

---

## ğŸ“‹ é¡¹ç›®ç›®æ ‡

ä¸º Job Autopilot é¡¹ç›®å®ç°ä¸“ä¸šçš„ç®€å†å¯¼å‡ºç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. **å¤šæ¨¡æ¿æ”¯æŒ**ï¼š4ç§ä¸“ä¸šç®€å†æ¨¡æ¿ï¼ˆClassic/Modern Ã— Single/Two Columnï¼‰
2. **AIæ™ºèƒ½å‹ç¼©**ï¼šå°† Master Resume å‹ç¼©åˆ°1é¡µï¼Œé’ˆå¯¹ç‰¹å®šèŒä½ä¼˜åŒ–
3. **äº¤äº’å¼ç¼–è¾‘**ï¼šåœ¨çº¿é¢„è§ˆã€Sectioné‡æ’ã€è¡Œé—´è·è°ƒæ•´
4. **å¤šæ ¼å¼æ”¯æŒ**ï¼šæ”¯æŒ MD/PDF/DOCX æ ¼å¼çš„ Master Resume è¾“å…¥
5. **ç‰ˆæœ¬å†å²**ï¼šä¿å­˜æ‰€æœ‰å¯¼å‡ºç‰ˆæœ¬ä¾›è¿½æº¯

---

## ğŸ¯ User Review Required

> [!IMPORTANT]
> **å…³é”®è®¾è®¡å†³ç­–éœ€è¦ç¡®è®¤**
> 
> 1. **Template Preview æ–¹æ¡ˆ**ï¼šä½¿ç”¨é™æ€ JPG æˆªå›¾ï¼ˆResume-Matcher æ–¹æ¡ˆï¼‰
>    - **åˆ›å»ºæ–¹æ³•**ï¼šç”¨è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆï¼ˆè¯¦è§ä¸‹æ–¹ "Template Preview åˆ›å»ºè„šæœ¬"ï¼‰
>    - **æ­¥éª¤**ï¼šç”Ÿæˆç¤ºä¾‹PDF â†’ pdf2imageè½¬PNG â†’ Pillowè£å‰ªä¸º300x400px â†’ ä¿å­˜ä¸ºJPG
>    - **å¤‡é€‰æ–¹æ¡ˆ**ï¼šå¦‚æœè„šæœ¬å¤±è´¥ï¼Œå¯ä»¥ç”¨ AI å›¾åƒç”Ÿæˆå·¥å…·ï¼ˆgenerate_imageï¼‰æˆ–æ‰‹åŠ¨è®¾è®¡
> 2. **Section Reordering**ï¼šåŒæ—¶æ”¯æŒ Drag-Dropï¼ˆstreamlit-sortablesï¼‰å’Œç®­å¤´æŒ‰é’®ï¼Œç¡®ä¿ç§»åŠ¨ç«¯å…¼å®¹
> 3. **Master Resume æ ¼å¼**ï¼šå¿…é¡»æ”¯æŒ MD/PDF/DOCX ä¸‰ç§æ ¼å¼ï¼Œéœ€è¦ PyPDF2 å’Œ python-docx è§£æ
> 4. **ä¾èµ–åŒ…å…¼å®¹æ€§**ï¼š`streamlit-sortables` éœ€è¦ Streamlit 1.30.0ï¼Œå¯èƒ½ä¸å…¶ä»–åŒ…å†²çª

> [!WARNING]
> **Breaking Changes**
> 
> - **æ•°æ®åº“ Schema å˜æ›´**ï¼šéœ€è¦åœ¨ `jobs` è¡¨æ–°å¢ 2 åˆ—ï¼ˆ`selected_template`, `resume_version_id`ï¼‰
> - **Dependencies å˜æ›´**ï¼šæ–°å¢ 4 ä¸ªä¾èµ–åŒ…ï¼ˆPillow, streamlit-sortables, PyPDF2, pdf2imageï¼‰
> - **æ–‡ä»¶ç»“æ„å˜æ›´**ï¼šæ–°å¢ `data/templates/` å’Œ `assets/templates/` ç›®å½•

> [!CAUTION]
> **å‰ç«¯æŠ€æœ¯æ ˆå†³ç­–ï¼šStreamlit vs React/Vue**
> 
> **é—®é¢˜**ï¼šç›®å‰ä½¿ç”¨ Streamlitï¼Œæ˜¯å¦åº”è¯¥è¿ç§»åˆ° React/Vueï¼Ÿ
> 
> **çŸ­æœŸå»ºè®®ï¼ˆç°é˜¶æ®µï¼‰**ï¼š**ç»§ç»­ä½¿ç”¨ Streamlit** âœ…
> - **ç†ç”±**ï¼š
>   - ä½ çš„é¡¹ç›®æ˜¯çº¯å¼€æº AGPL-3.0 é¡¹ç›®ï¼Œç”¨ AI å†™ä»£ç ï¼ŒStreamlit å¼€å‘é€Ÿåº¦è¿œè¶… React
>   - Resume Export åŠŸèƒ½ç”¨ Streamlit å®Œå…¨å¤Ÿç”¨ï¼ˆæ–‡ä»¶ä¸Šä¼ ã€æ¨¡æ¿é€‰æ‹©ã€å¯¼å‡ºæŒ‰é’®éƒ½æ”¯æŒï¼‰
>   - `streamlit-sortables` æä¾›äº† drag-drop åŠŸèƒ½ï¼Œä½“éªŒå°šå¯
>   - å½“å‰é¡¹ç›®å·²ç»æ˜¯ Streamlitï¼Œé‡æ„æˆæœ¬é«˜ï¼ˆé¢„è®¡ +20 å°æ—¶å·¥ä½œé‡ï¼‰
> 
> - **Streamlit UI ä¼˜åŒ–å»ºè®®**ï¼ˆä¿ç•™ Streamlitï¼Œä½†æå‡è§†è§‰æ•ˆæœï¼‰ï¼š
>   - ä½¿ç”¨ **Custom CSS** ç¾åŒ–ç•Œé¢ï¼ˆgradients, shadows, hover effectsï¼‰
>   - æ·»åŠ  **streamlit-extras** åº“ï¼ˆcolored headers, metric cards, animated iconsï¼‰
>   - é›†æˆ **streamlit-option-menu** å®ç°ä¾§è¾¹æ èœå•ï¼ˆç±»ä¼¼ SaaS äº§å“ï¼‰
>   - ä½¿ç”¨ **streamlit-lottie** æ·»åŠ åŠ¨ç”» loading æ•ˆæœ
>   - å‚è€ƒ **Streamlit Gallery** çš„ä¼˜ç§€ UI æ¡ˆä¾‹
>   - è¯¦è§ä¸‹æ–¹ "Streamlit UI ä¼˜åŒ–æ–¹æ¡ˆ"
> 
> **é•¿æœŸå»ºè®®ï¼ˆ6ä¸ªæœˆåï¼‰**ï¼šå¦‚æœæ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼Œè€ƒè™‘è¿ç§»åˆ° **React + Next.js**
> - âœ… ä½ æ‰“ç®—å°† Job Autopilot å•†ä¸šåŒ–ï¼ˆå–ç»™å…¶ä»–æ±‚èŒè€…ï¼‰
> - âœ… éœ€è¦æ”¯æŒé«˜å¹¶å‘ï¼ˆ100+ åŒæ—¶åœ¨çº¿ç”¨æˆ·ï¼‰
> - âœ… éœ€è¦æ›´å¤æ‚çš„äº¤äº’ï¼ˆå®æ—¶åä½œç¼–è¾‘ç®€å†ã€æ‹–æ‹½å¼ç®€å†æ„å»ºå™¨ï¼‰
> - âœ… éœ€è¦ç§»åŠ¨ç«¯ Appï¼ˆReact Nativeï¼‰
> - âœ… éœ€è¦ SEO ä¼˜åŒ–ï¼ˆå…¬å¼€ç½‘ç«™ï¼‰
> 
> **è¿ç§»è·¯å¾„ï¼ˆå¦‚æœæœªæ¥éœ€è¦ï¼‰**ï¼š
> 1. **Phase 1**ï¼šä¿ç•™ Streamlitï¼Œå…ˆå®ç°æ‰€æœ‰åŠŸèƒ½
> 2. **Phase 2**ï¼šåç«¯æ”¹é€ ä¸º FastAPI REST APIï¼ˆç‹¬ç«‹äºå‰ç«¯ï¼‰
> 3. **Phase 3**ï¼šç”¨ React + Next.js é‡å†™å‰ç«¯ï¼Œè°ƒç”¨ FastAPI
> 4. **Phase 4**ï¼šé€æ­¥æ·˜æ±° Streamlit ç‰ˆæœ¬
> 
> **ç»“è®º**ï¼šæœ¬æ¬¡å®æ–½ç»§ç»­ç”¨ Streamlitï¼Œä¸åšå‰ç«¯é‡æ„

---

## ğŸ¨ Streamlit UI ä¼˜åŒ–æ–¹æ¡ˆ

åŸºäºä½ çš„éœ€æ±‚ï¼ˆ"æˆ‘ä»¬ä¹‹åå¯ä»¥ä¼˜åŒ– Streamlit çš„ UI"ï¼‰ï¼Œè¿™é‡Œæä¾›å®Œæ•´çš„ Streamlit ç¾åŒ–æ–¹æ¡ˆï¼š

### ä¼˜åŒ–ç›®æ ‡
- ä¿ç•™ Streamlitï¼ˆPython å…¨æ ˆï¼‰
- æå‡è§†è§‰æ•ˆæœï¼Œæ¥è¿‘ä¸“ä¸š SaaS äº§å“æ°´å¹³
- æ·»åŠ ç°ä»£åŒ–äº¤äº’ï¼ˆåŠ¨ç”»ã€æ¸å˜ã€hover æ•ˆæœï¼‰

### æ¨èçš„ Streamlit å¢å¼ºåº“

```txt
# requirements.txt (æ–°å¢)
streamlit-extras==0.3.6        # Colored headers, metric cards, badges
streamlit-option-menu==0.3.6   # ä¸“ä¸šä¾§è¾¹æ èœå•
streamlit-lottie==0.0.5        # åŠ¨ç”» loading æ•ˆæœ
streamlit-card==0.0.4          # å¡ç‰‡ç»„ä»¶
```

### å…·ä½“ä¼˜åŒ–æ–¹æ¡ˆ

#### 1. **Custom CSS ç¾åŒ–**ï¼ˆæœ€é‡è¦ï¼‰

```python
# In streamlit_app.py
st.markdown("""
<style>
    /* éšè—é»˜è®¤ Streamlit å…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* ä¸»é¢˜è‰² */
    :root {
        --primary-color: #667eea;
        --secondary-color: #764ba2;
        --background: #f8f9fa;
        --card-bg: #ffffff;
    }
    
    /* æ¸å˜èƒŒæ™¯ */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    
    /* å¡ç‰‡æ ·å¼ï¼ˆå¸¦é˜´å½±å’Œ hover æ•ˆæœï¼‰ */
    .element-container {
        background: var(--card-bg);
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .element-container:hover {
        box-shadow: 0 8px 12px rgba(0,0,0,0.15);
        transform: translateY(-2px);
    }
    
    /* æŒ‰é’®ç¾åŒ– */
    .stButton>button {
        background: linear-gradient(90deg, #667eea, #764ba2);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        transition: all 0.3s;
    }
    
    .stButton>button:hover {
        transform: scale(1.05);
        box-shadow: 0 6px 20px rgba(102,126,234,0.4);
    }
    
    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput>div>div>input {
        border-radius: 8px;
        border: 2px solid #e0e0e0;
        padding: 0.75rem;
        transition: border 0.3s;
    }
    
    .stTextInput>div>div>input:focus {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px rgba(102,126,234,0.1);
    }
    
    /* è¿›åº¦æ¡ç¾åŒ– */
    .stProgress > div > div > div {
        background: linear-gradient(90deg, #667eea, #764ba2);
    }
</style>
""", unsafe_allow_html=True)
```

#### 2. **ä¸“ä¸šä¾§è¾¹æ èœå•**

```python
from streamlit_option_menu import option_menu

# Replace st.radio with option_menu
with st.sidebar:
    st.image("assets/logo.png", width=150)  # Add logo
    
    page = option_menu(
        menu_title="Navigation",
        options=["ğŸ” Job Search", "ğŸ“„ Resume Export", "ğŸ“Š Dashboard", "âš™ï¸ Settings"],
        icons=["search", "file-earmark-text", "bar-chart", "gear"],
        menu_icon="cast",
        default_index=0,
        styles={
            "container": {"padding": "0!important", "background-color": "#fafafa"},
            "icon": {"color": "#667eea", "font-size": "18px"},
            "nav-link": {
                "font-size": "14px",
                "text-align": "left",
                "margin": "0px",
                "--hover-color": "#eee"
            },
            "nav-link-selected": {"background-color": "#667eea"},
        }
    )
```

#### 3. **åŠ¨ç”» Loading æ•ˆæœ**

```python
from streamlit_lottie import st_lottie
import requests

def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

# Use in Resume Export
lottie_loading = load_lottieurl("https://assets5.lottiefiles.com/packages/lf20_usmfx6bp.json")

with st.spinner(""):
    st_lottie(lottie_loading, height=200, key="loading")
    tailored_resume = resume_generator.tailor_resume(...)
```

#### 4. **å¢å¼ºçš„ Metric Cards**

```python
from streamlit_extras.metric_cards import style_metric_cards

col1, col2, col3 = st.columns(3)

with col1:
    st.metric("Jobs Found", len(st.session_state.jobs), delta="+5 today")
with col2:
    st.metric("High Matches", high_match_count, delta="+2")
with col3:
    st.metric("Applications", app_count, delta="+10 this week")

# Apply gradient styling
style_metric_cards(
    background_color="#ffffff",
    border_left_color="#667eea",
    border_size_px=4,
    border_radius_px=12,
    box_shadow=True
)
```

#### 5. **Template Selectorï¼ˆç¾åŒ–å¡ç‰‡ï¼‰**

```python
from streamlit_card import card

st.markdown("### Choose a Template")
cols = st.columns(4)

templates = [
    {"name": "Classic Single", "img": "classic_single.jpg", "desc": "ATS-friendly"},
    {"name": "Modern Single", "img": "modern_single.jpg", "desc": "Clean design"},
    {"name": "Classic Two", "img": "classic_two.jpg", "desc": "Professional"},
    {"name": "Modern Two", "img": "modern_two.jpg", "desc": "Contemporary"}
]

for i, template in enumerate(templates):
    with cols[i]:
        has_clicked = card(
            title=template["name"],
            text=template["desc"],
            image=f"assets/templates/{template['img']}",
            styles={
                "card": {
                    "width": "100%",
                    "height": "300px",
                    "border-radius": "10px",
                    "box-shadow": "0 4px 6px rgba(0,0,0,0.1)",
                },
                "filter": {
                    "background-color": "rgba(0,0,0,0)"
                }
            }
        )
        
        if has_clicked:
            st.session_state.selected_template = template["name"]
```

#### 6. **Progress Indicatorï¼ˆæ­¥éª¤å¯¼èˆªï¼‰**

```python
from streamlit_extras.app_logo import add_logo
from streamlit_extras.colored_header import colored_header

# Step-by-step progress
steps = ["Upload Resume", "Select Template", "Customize", "AI Compression", "Export"]
current_step = st.session_state.get("current_step", 0)

# Progress bar
st.progress(current_step / len(steps))

# Visual step indicator
cols = st.columns(len(steps))
for i, step in enumerate(steps):
    with cols[i]:
        if i < current_step:
            st.markdown(f"âœ… **{step}**")
        elif i == current_step:
            st.markdown(f"ğŸ”µ **{step}**")
        else:
            st.markdown(f"âšª {step}")
```

### å®æ–½æ—¶é—´çº¿

- **Phase 1 Foundation**ï¼ˆ+15 åˆ†é’Ÿï¼‰ï¼šå®‰è£… streamlit-extras, streamlit-option-menu
- **Phase 3 Frontend**ï¼ˆå·²åŒ…å«ï¼‰ï¼šé›†æˆ Custom CSS å’Œç¾åŒ–ç»„ä»¶
- **Phase 5 Polish**ï¼ˆ+30 åˆ†é’Ÿï¼‰ï¼šæ·»åŠ  Lottie åŠ¨ç”»å’Œæœ€ç»ˆæ‰“ç£¨

### å‚è€ƒèµ„æº

- [Streamlit Gallery](https://streamlit.io/gallery) - ä¼˜ç§€ UI æ¡ˆä¾‹
- [Streamlit Extras Docs](https://extras.streamlit.app/)
- [streamlit-option-menu Demo](https://github.com/victoryhb/streamlit-option-menu)
- [Lottie Files](https://lottiefiles.com/) - å…è´¹åŠ¨ç”»ç´ æ

---

## ğŸ“Š Proposed Changes

### Component 1: æ¨¡æ¿ç³»ç»Ÿ (Template System)

#### [NEW] [classic_single_column.json](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/data/templates/classic_single_column.json)
```json
{
  "name": "Classic Single Column",
  "description": "Traditional ATS-friendly layout",
  "sections": ["header", "summary", "experience", "education", "skills"],
  "section_order": ["summary", "experience", "skills", "education"],
  "line_spacing": 1.0,
  "margins": {"top": 0.5, "bottom": 0.5, "left": 0.7, "right": 0.7},
  "fonts": {
    "name": {"family": "Arial", "size": 16, "bold": true},
    "heading": {"family": "Arial", "size": 11, "bold": true},
    "body": {"family": "Arial", "size": 10, "bold": false}
  }
}
```

**ç†ç”±**ï¼šClassic å•æ æ¨¡æ¿æ˜¯ ATS æœ€å‹å¥½çš„æ ¼å¼ï¼Œæ— è¡¨æ ¼æ— å¤æ‚æ’ç‰ˆã€‚

---

#### [NEW] [modern_single_column.json](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/data/templates/modern_single_column.json)
```json
{
  "name": "Modern Single Column",
  "description": "Clean design with accent colors",
  "sections": ["header", "summary", "experience", "skills", "education"],
  "section_order": ["summary", "skills", "experience", "education"],
  "line_spacing": 1.15,
  "use_accent_color": true,
  "accent_color": "#667eea",
  "margins": {"top": 0.5, "bottom": 0.5, "left": 0.7, "right": 0.7},
  "fonts": {
    "name": {"family": "Calibri", "size": 18, "bold": true},
    "heading": {"family": "Calibri", "size": 11, "bold": true},
    "body": {"family": "Calibri", "size": 10, "bold": false}
  }
}
```

**ç†ç”±**ï¼šModern é£æ ¼é€‚åˆåˆ›æ„/ç§‘æŠ€è¡Œä¸šï¼Œçªå‡º Skills éƒ¨åˆ†ã€‚

---

#### [NEW] [classic_two_column.json](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/data/templates/classic_two_column.json)
```json
{
  "name": "Classic Two Column",
  "description": "Professional dual-column layout",
  "layout": "two_column",
  "left_column": ["contact", "skills", "education"],
  "right_column": ["summary", "experience"],
  "left_width": 0.35,
  "right_width": 0.65,
  "line_spacing": 1.0,
  "margins": {"top": 0.5, "bottom": 0.5, "left": 0.6, "right": 0.6},
  "fonts": {
    "name": {"family": "Times New Roman", "size": 16, "bold": true},
    "heading": {"family": "Times New Roman", "size": 11, "bold": true},
    "body": {"family": "Times New Roman", "size": 10, "bold": false}
  }
}
```

**ç†ç”±**ï¼šä¸¤æ å¸ƒå±€èŠ‚çœç©ºé—´ï¼Œé€‚åˆå†…å®¹è¾ƒå¤šçš„ç®€å†ã€‚

---

#### [NEW] [modern_two_column.json](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/data/templates/modern_two_column.json)
```json
{
  "name": "Modern Two Column",
  "description": "Contemporary dual-column with sidebar",
  "layout": "two_column",
  "left_column": ["contact", "skills", "certifications"],
  "right_column": ["summary", "experience", "education"],
  "left_width": 0.30,
  "right_width": 0.70,
  "sidebar_background": "#f5f5f5",
  "line_spacing": 1.1,
  "use_accent_color": true,
  "accent_color": "#764ba2",
  "margins": {"top": 0.4, "bottom": 0.4, "left": 0.5, "right": 0.5},
  "fonts": {
    "name": {"family": "Helvetica", "size": 18, "bold": true},
    "heading": {"family": "Helvetica", "size": 11, "bold": true},
    "body": {"family": "Helvetica", "size": 10, "bold": false}
  }
}
```

**ç†ç”±**ï¼šæœ€ç°ä»£åŒ–çš„è®¾è®¡ï¼Œå¸¦ä¾§è¾¹æ èƒŒæ™¯è‰²ï¼Œé€‚åˆè®¾è®¡/äº§å“å²—ä½ã€‚

---

#### [NEW] Template Preview Images
- [classic_single.jpg](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/assets/templates/classic_single.jpg) (300x400px)
- [modern_single.jpg](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/assets/templates/modern_single.jpg) (300x400px)
- [classic_two.jpg](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/assets/templates/classic_two.jpg) (300x400px)
- [modern_two.jpg](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/assets/templates/modern_two.jpg) (300x400px)

**è‡ªåŠ¨åŒ–åˆ›å»ºè„šæœ¬**ï¼š

```python
# scripts/generate_template_previews.py
"""
è‡ªåŠ¨ç”Ÿæˆ4å¼ æ¨¡æ¿é¢„è§ˆå›¾
ä¾èµ–ï¼šreportlab, pdf2image, Pillow, poppler
"""
import os
from modules.resume_generator import ResumeGenerator
from pdf2image import convert_from_path
from PIL import Image

def generate_preview_images():
    """Generate template preview images automatically"""
    gen = ResumeGenerator()
    
    # Sample resume data
    sample_resume = {
        "name": "Jane Smith",
        "contact": {"email": "jane@example.com", "phone": "555-0123", "location": "Toronto, ON"},
        "summary": "Experienced professional with 5+ years in product management and AI.",
        "experience": [
            {
                "title": "Senior Product Manager",
                "company": "Tech Corp",
                "duration": "2020-Present",
                "details": [
                    "Led AI product development resulting in 30% revenue growth",
                    "Managed team of 5 engineers and 2 designers"
                ]
            },
            {
                "title": "Product Manager",
                "company": "StartupCo",
                "duration": "2018-2020",
                "details": [
                    "Launched 3 successful products with 10K+ users",
                    "Conducted user research and analyzed metrics"
                ]
            }
        ],
        "education": [
            {"title": "MBA, Business Administration", "details": ["University of Toronto, 2018"]}
        ],
        "skills": ["Product Management", "AI/ML", "Python", "SQL", "Agile"]
    }
    
    templates = ["classic_single_column", "modern_single_column", 
                 "classic_two_column", "modern_two_column"]
    
    os.makedirs("assets/templates", exist_ok=True)
    
    for i, template_name in enumerate(templates):
        print(f"Generating preview for {template_name}...")
        
        # 1. Load template and generate PDF
        template = gen.load_template(template_name)
        pdf_path = f"temp_{template_name}.pdf"
        gen.export_pdf(sample_resume, pdf_path)
        
        # 2. Convert PDF to PNG (first page only)
        images = convert_from_path(pdf_path, dpi=150, first_page=1, last_page=1)
        png_image = images[0]
        
        # 3. Crop to 300x400px (resize proportionally)
        width, height = png_image.size
        aspect_ratio = 300 / 400  # target aspect
        current_ratio = width / height
        
        if current_ratio > aspect_ratio:
            # Too wide, crop width
            new_width = int(height * aspect_ratio)
            left = (width - new_width) // 2
            png_image = png_image.crop((left, 0, left + new_width, height))
        else:
            # Too tall, crop height
            new_height = int(width / aspect_ratio)
            top = (height - new_height) // 2
            png_image = png_image.crop((0, top, width, top + new_height))
        
        # 4. Resize to exactly 300x400
        png_image = png_image.resize((300, 400), Image.LANCZOS)
        
        # 5. Save as JPG
        jpg_name = template_name.replace("_column", "").replace("_", "_")
        if "single" in template_name:
            jpg_name = "classic_single.jpg" if "classic" in template_name else "modern_single.jpg"
        else:
            jpg_name = "classic_two.jpg" if "classic" in template_name else "modern_two.jpg"
        
        jpg_path = f"assets/templates/{jpg_name}"
        png_image.convert("RGB").save(jpg_path, "JPEG", quality=90)
        
        # Clean up temp PDF
        os.remove(pdf_path)
        print(f"âœ… Saved {jpg_path}")
    
    print("\nâœ… All template previews generated!")

if __name__ == "__main__":
    generate_preview_images()
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# ç¡®ä¿å·²å®‰è£…ä¾èµ–
pip install pdf2image Pillow reportlab

# Windows éœ€è¦ä¸‹è½½ popplerï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰
# ç„¶åè¿è¡Œè„šæœ¬
python scripts/generate_template_previews.py
```

**Windows Poppler å®‰è£…**ï¼š
1. ä¸‹è½½ï¼šhttps://github.com/oschwartz10612/poppler-windows/releases
2. **è§£å‹åˆ°ä»»æ„ä½ç½®**ï¼ˆä¾‹å¦‚ `C:\poppler` æˆ– `D:\tools\poppler`ï¼Œ**ä¸éœ€è¦æ”¾åœ¨é¡¹ç›®æ–‡ä»¶å¤¹å†…**ï¼‰
3. æ·»åŠ åˆ°ç³»ç»Ÿ PATHï¼š`C:\poppler\Library\bin`ï¼ˆæˆ–ä½ è§£å‹çš„è·¯å¾„ + `\Library\bin`ï¼‰
4. é‡å¯ç»ˆç«¯éªŒè¯ï¼š`pdftoppm -h`ï¼ˆåº”è¯¥æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ï¼Œä¸æŠ¥é”™ï¼‰

**æ³¨æ„**ï¼š
- Poppler æ˜¯**ç³»ç»Ÿçº§å·¥å…·**ï¼Œä¸æ˜¯ Python åŒ…ï¼Œæ‰€ä»¥ä»»æ„ä½ç½®éƒ½å¯ä»¥
- åªè¦åœ¨ PATH ä¸­ï¼ŒPython çš„ `pdf2image` å°±èƒ½æ‰¾åˆ°å®ƒ
- å¦‚æœä½ ä¸æƒ³ä¿®æ”¹ç³»ç»Ÿ PATHï¼Œä¹Ÿå¯ä»¥åœ¨ä»£ç ä¸­æŒ‡å®šè·¯å¾„ï¼š
  ```python
  from pdf2image import convert_from_path
  images = convert_from_path(pdf_path, poppler_path=r"C:\poppler\Library\bin")
  ```

**å¤‡é€‰æ–¹æ¡ˆï¼ˆå¦‚æœè„šæœ¬å¤±è´¥ï¼‰**ï¼š
- ç”¨ AI ç”Ÿæˆå·¥å…·ï¼š`generate_image(prompt="Professional resume template preview, classic single column layout, clean design")`
- æ‰‹åŠ¨è®¾è®¡ï¼šCanva/Figr/PowerPoint è®¾è®¡ç®€å†æ¨¡æ¿æˆªå›¾

---

### Component 2: åç«¯é€»è¾‘ (Backend)

#### [MODIFY] [resume_generator.py](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/modules/resume_generator.py)

**æ–°å¢åŠŸèƒ½**ï¼š
1. **Template System**
   - `load_template(template_name: str) -> Dict`ï¼šåŠ è½½æ¨¡æ¿ JSON
   - `apply_template(resume_data: Dict, template: Dict) -> Dict`ï¼šåº”ç”¨æ¨¡æ¿é…ç½®

2. **Multi-Format Parser**
   - `parse_pdf_resume(pdf_path: str) -> Dict`ï¼šç”¨ PyPDF2 æå–æ–‡æœ¬ + AI ç»“æ„åŒ–
   - `parse_docx_resume(docx_path: str) -> Dict`ï¼šç”¨ python-docx æå–å†…å®¹ + AI ç»“æ„åŒ–
   - `load_master_resume()` æ‰©å±•ä¸ºæ”¯æŒ `.pdf` å’Œ `.docx`

3. **AI Compression**
   - `compress_to_one_page(resume_data: Dict, job_description: str) -> List[Dict]`
   - è¿”å› 3 ä¸ªå‹ç¼©ç‰ˆæœ¬ï¼ˆAggressive/Balanced/Conservativeï¼‰
   - ç”¨ `tiktoken` ä¼°ç®—å­—æ•°ç¡®ä¿ 1 é¡µå†…ï¼ˆ~600 wordsï¼‰

4. **Version History**
   - `save_version(resume_data: Dict, job_id: int, template: str) -> int`
   - ä¿å­˜åˆ°æ•°æ®åº“ `resume_versions` è¡¨

**ä»£ç ç¤ºä¾‹ï¼ˆéƒ¨åˆ†ï¼‰**ï¼š
```python
def load_template(self, template_name: str) -> Dict:
    """Load template configuration from JSON"""
    template_path = f"data/templates/{template_name}.json"
    if not os.path.exists(template_path):
        app_logger.error(f"Template not found: {template_name}")
        return None
    
    with open(template_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def parse_pdf_resume(self, pdf_path: str) -> Dict:
    """Parse PDF resume using PyPDF2 + AI"""
    import PyPDF2
    
    with open(pdf_path, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    
    # Use AI to structure
    prompt = f"""Parse this resume text into structured JSON:
{text[:2000]}

Return JSON with keys: name, contact, summary, experience, education, skills"""
    
    response = ai_agent.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    result = response.choices[0].message.content
    # Extract and parse JSON...
    return json.loads(result)
```

---

#### [MODIFY] [database.py](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/modules/database.py)

**Schema å˜æ›´**ï¼š

```python
# Add to Job model
class Job(Base):
    # ... existing fields ...
    selected_template = Column(String(50))  # e.g. "classic_single_column"
    resume_version_id = Column(Integer, ForeignKey('resume_versions.id'))

# New model
class ResumeVersion(Base):
    __tablename__ = 'resume_versions'
    
    id = Column(Integer, primary_key=True)
    job_id = Column(Integer, ForeignKey('jobs.id'))
    template_name = Column(String(50))
    resume_data = Column(JSON)  # Full resume JSON
    created_at = Column(DateTime, default=datetime.utcnow)
    file_path_docx = Column(String(255))
    file_path_pdf = Column(String(255))
```

**Migration Script**ï¼š
```python
# scripts/init_database.py
def upgrade():
    op.add_column('jobs', sa.Column('selected_template', sa.String(50)))
    op.add_column('jobs', sa.Column('resume_version_id', sa.Integer))
    op.create_table('resume_versions', ...)
```

---

### Component 3: å‰ç«¯ UI (Frontend)

#### [MODIFY] [streamlit_app.py](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/streamlit_app.py)

**æ–°å¢é¡µé¢**ï¼šåœ¨ Sidebar å¯¼èˆªæ–°å¢ `"ğŸ“„ Resume Export"`

**UI ç»“æ„**ï¼š
```
ğŸ“„ Resume Export
â”œâ”€â”€ Step 1: Upload Master Resume
â”‚   â””â”€â”€ File uploader (MD/PDF/DOCX)
â”œâ”€â”€ Step 2: Select Job (optional)
â”‚   â””â”€â”€ Dropdown from cached jobs
â”œâ”€â”€ Step 3: Choose Template
â”‚   â””â”€â”€ 4 cards with preview images
â”œâ”€â”€ Step 4: Customize Resume
â”‚   â”œâ”€â”€ Section Reordering (drag or arrows)
â”‚   â”œâ”€â”€ Inline Editors (Summary, Experience)
â”‚   â”œâ”€â”€ Line Spacing Slider (0.8-1.5)
â”‚   â””â”€â”€ Page Preview (word count + 1-page estimate)
â”œâ”€â”€ Step 5: AI Compression
â”‚   â””â”€â”€ 3 options (Aggressive/Balanced/Conservative)
â””â”€â”€ Step 6: Export
    â”œâ”€â”€ Download DOCX
    â”œâ”€â”€ Download PDF
    â””â”€â”€ Save to Version History
```

**å…³é”®ä»£ç **ï¼ˆSection Reorderingï¼‰ï¼š
```python
import streamlit as st
from streamlit_sortables import sort_items

st.markdown("### Reorder Resume Sections")

# Method 1: Drag-drop
sections = ["Summary", "Experience", "Skills", "Education"]
reordered = sort_items(sections, key="section_order")

# Method 2: Arrow buttons (fallback)
st.markdown("**Or use arrow buttons:**")
for i, section in enumerate(sections):
    col1, col2, col3 = st.columns([3, 1, 1])
    col1.write(section)
    if i > 0:
        if col2.button("â¬†ï¸", key=f"up_{section}"):
            sections[i], sections[i-1] = sections[i-1], sections[i]
    if i < len(sections) - 1:
        if col3.button("â¬‡ï¸", key=f"down_{section}"):
            sections[i], sections[i+1] = sections[i+1], sections[i]
```

**Template Selector**ï¼š
```python
st.markdown("### Choose a Template")
cols = st.columns(4)

templates = ["classic_single", "modern_single", "classic_two", "modern_two"]
for i, template in enumerate(templates):
    with cols[i]:
        st.image(f"assets/templates/{template}.jpg", use_container_width=True)
        if st.button(f"Select", key=f"select_{template}"):
            st.session_state.selected_template = template
            st.success(f"Selected: {template}")
```

---

### Component 4: ä¾èµ–ç®¡ç† (Dependencies)

#### [MODIFY] [requirements.txt](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/requirements.txt)

**æ–°å¢ä¾èµ–**ï¼š
```txt
# Resume Export (NEW)
streamlit-sortables==0.2.0  # Drag-drop section reorder
PyPDF2==3.0.1               # PDF parsing
pdf2image==1.16.3           # PDF to image (for template previews)
# Pillow==10.1.0            # Already installed (upgrade to 10.0.0)
# python-docx==1.1.0        # Already installed
# reportlab==4.0.7          # Already installed
```

> [!CAUTION]
> **ä¾èµ–å†²çªé£é™©**
> 
> - `streamlit-sortables==0.2.0` è¦æ±‚ `streamlit>=1.30.0`ï¼Œä½ çš„ requirements.txt å·²ç»æ˜¯ 1.30.0ï¼Œå…¼å®¹ âœ…
> - `pdf2image` éœ€è¦ç³»ç»Ÿå®‰è£… **poppler**ï¼ˆWindows éœ€æ‰‹åŠ¨ä¸‹è½½ï¼‰
> - `Pillow` ä» 10.1.0 é™çº§åˆ° 10.0.0ï¼ˆç”¨æˆ·è¦æ±‚ï¼‰ï¼Œå¯èƒ½æœ‰ breaking changes

**å®‰è£…å‘½ä»¤**ï¼š
```bash
pip install streamlit-sortables==0.2.0 PyPDF2==3.0.1 pdf2image==1.16.3 --no-cache-dir
```

---

### Component 5: æµ‹è¯•ä¸éªŒè¯ (Testing)

#### [NEW] [test_dependencies.py](file:///c:/Users/Schlaflied/Desktop/Job%20Autopilot/scripts/test_dependencies.py)

```python
import sys

deps = [
    ("PIL", "Pillow"),
    ("PyPDF2", "PyPDF2"),
    ("streamlit_sortables", "streamlit-sortables"),
    ("pdf2image", "pdf2image"),
]

for mod, pkg in deps:
    try:
        __import__(mod)
        print(f"âœ… {pkg}")
    except ImportError as e:
        print(f"âŒ {pkg}: {e}")
        sys.exit(1)

print("\nâœ… All dependencies installed!")
```

**è¿è¡Œæ–¹å¼**ï¼š
```bash
python scripts/test_dependencies.py
```

---

## ğŸ”§ Verification Plan

### Automated Tests

1. **ä¾èµ–å®‰è£…æµ‹è¯•**
   ```bash
   python scripts/test_dependencies.py
   ```

2. **æ¨¡æ¿åŠ è½½æµ‹è¯•**
   ```python
   # Test all 4 templates load correctly
   from modules.resume_generator import resume_generator
   
   templates = ["classic_single_column", "modern_single_column", 
                "classic_two_column", "modern_two_column"]
   for t in templates:
       template = resume_generator.load_template(t)
       assert template is not None, f"{t} failed to load"
   ```

3. **Multi-Format Resume è§£ææµ‹è¯•**
   ```python
   # Test MD/PDF/DOCX parsing
   master_md = resume_generator.load_master_resume("Yuting Sun Master Resume.md")
   assert master_md['name'] == "Yuting Sun"
   
   # (éœ€è¦å‡†å¤‡æµ‹è¯•ç”¨çš„ PDF å’Œ DOCX æ–‡ä»¶)
   ```

4. **AI å‹ç¼©æµ‹è¯•**
   ```python
   # Test 1-page compression generates 3 versions
   versions = resume_generator.compress_to_one_page(master_md, job_description)
   assert len(versions) == 3
   assert all(v['word_count'] <= 600 for v in versions)
   ```

### Manual Verification

1. **UI åŠŸèƒ½æµ‹è¯•**
   - [ ] Upload MD/PDF/DOCX master resume
   - [ ] Template preview images æ­£ç¡®æ˜¾ç¤º
   - [ ] Drag-drop section reorder å·¥ä½œæ­£å¸¸
   - [ ] Arrow buttons å¯ä»¥ç§»åŠ¨ sections
   - [ ] Line spacing slider å½±å“é¢„è§ˆ
   - [ ] AI compression ç”Ÿæˆ 3 ä¸ªé€‰é¡¹
   - [ ] Export DOCX/PDF æˆåŠŸä¸‹è½½

2. **1é¡µçº¦æŸéªŒè¯**
   - [ ] ç”¨çœŸå®ç®€å†æµ‹è¯•ï¼Œ95%+ æƒ…å†µä¸‹å¯¼å‡ºç»“æœæ˜¯ 1 é¡µ
   - [ ] Word count estimator å‡†ç¡®ï¼ˆtolerance Â±50 wordsï¼‰

3. **Version History**
   - [ ] æ¯æ¬¡å¯¼å‡ºä¿å­˜åˆ°æ•°æ®åº“
   - [ ] å¯ä»¥æŸ¥çœ‹å†å²ç‰ˆæœ¬
   - [ ] å¯ä»¥é‡æ–°ä¸‹è½½æ—§ç‰ˆæœ¬

---

## ğŸ“… Implementation Phases

### Phase 1: Foundationï¼ˆé¢„è®¡ 30 åˆ†é’Ÿï¼‰
- [x] åˆ›å»º 4 ä¸ª template JSON æ–‡ä»¶
- [x] ç”Ÿæˆ 4 å¼  preview å›¾ç‰‡ï¼ˆæ‰‹åŠ¨æˆ–è„šæœ¬ï¼‰
- [x] æ›´æ–° database schemaï¼ˆmigration scriptï¼‰
- [x] å®‰è£…æ–°ä¾èµ–åŒ…

### Phase 2: Backendï¼ˆé¢„è®¡ 1.5 å°æ—¶ï¼‰
- [ ] å®ç° `load_template()`
- [ ] å®ç° `parse_pdf_resume()` å’Œ `parse_docx_resume()`
- [ ] å®ç° `compress_to_one_page()`ï¼ˆAI 3 ç‰ˆæœ¬å‹ç¼©ï¼‰
- [ ] å®ç° `save_version()` å’Œ `get_version_history()`
- [ ] æ›´æ–° `export_docx()` å’Œ `export_pdf()` æ”¯æŒæ¨¡æ¿

### Phase 3: Frontendï¼ˆé¢„è®¡ 2 å°æ—¶ï¼‰
- [ ] æ–°å¢ "Resume Export" é¡µé¢åˆ° sidebar
- [ ] å®ç° Step 1: File uploader
- [ ] å®ç° Step 3: Template selectorï¼ˆ4 cards with imagesï¼‰
- [ ] å®ç° Step 4: Section reorderingï¼ˆdrag-drop + arrowsï¼‰
- [ ] å®ç° Step 4: Inline editors + line spacing
- [ ] å®ç° Step 5: AI compression 3 options
- [ ] å®ç° Step 6: Export buttons + version history

### Phase 4: Testingï¼ˆé¢„è®¡ 30 åˆ†é’Ÿï¼‰
- [ ] è¿è¡Œ `test_dependencies.py`
- [ ] æµ‹è¯•æ‰€æœ‰ 4 ä¸ªæ¨¡æ¿å¯¼å‡º
- [ ] æµ‹è¯• MD/PDF/DOCX è§£æ
- [ ] éªŒè¯ 1 é¡µçº¦æŸï¼ˆçœŸå®ç®€å†ï¼‰
- [ ] Bug fixes

---

## ğŸ“Š Success Criteria

å®Œæˆåå¿…é¡»æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š

- [x] **4 Templates Work**ï¼šæ‰€æœ‰æ¨¡æ¿æ­£ç¡®æ¸²æŸ“ï¼Œæ— æ ¼å¼é”™è¯¯
- [x] **Multi-Format Support**ï¼šMD/PDF/DOCX éƒ½èƒ½æ­£ç¡®è§£æ
- [x] **Drag-drop OR Buttons**ï¼šè‡³å°‘ä¸€ç§ section reordering æ–¹å¼å·¥ä½œ
- [x] **Line Spacing Adjustable**ï¼šslider å½±å“å¯¼å‡ºç»“æœ
- [x] **95%+ One-Page**ï¼šç”¨çœŸå®æ•°æ®æµ‹è¯•ï¼Œç»å¤§éƒ¨åˆ†ç®€å†å‹ç¼©åˆ° 1 é¡µ
- [x] **Version History**ï¼šæ¯æ¬¡å¯¼å‡ºä¿å­˜åˆ°æ•°æ®åº“ï¼Œå¯è¿½æº¯
- [x] **AI Compression**ï¼šç”Ÿæˆ 3 ä¸ªå‹ç¼©é€‰é¡¹ï¼ˆAggressive/Balanced/Conservativeï¼‰

---

## ğŸš¨ ä½ å¯èƒ½é—æ¼çš„å…¶ä»–é—®é¢˜

åŸºäºæˆ‘çš„åˆ†æï¼Œè¿™é‡Œæ˜¯ä¸€äº›ä½ å¯èƒ½æ²¡æ³¨æ„åˆ°çš„æ½œåœ¨é—®é¢˜ï¼š

### 1. **Poppler å®‰è£…é—®é¢˜**ï¼ˆWindows é«˜é£é™©ï¼‰âš ï¸

**é—®é¢˜**ï¼š`pdf2image` ä¾èµ–ç³»ç»Ÿçº§å·¥å…· popplerï¼ŒWindows æ²¡æœ‰å†…ç½®ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨ implementation plan ä¸­å·²ç»æ·»åŠ äº†è¯¦ç»†çš„å®‰è£…æ­¥éª¤
- **å»ºè®®**ï¼šåœ¨ Phase 1 Foundation é˜¶æ®µï¼Œå…ˆæµ‹è¯• poppler æ˜¯å¦èƒ½ç”¨
- **å¤‡é€‰æ–¹æ¡ˆ**ï¼šå¦‚æœ poppler å®‰è£…å¤±è´¥ï¼Œç”¨ AI å›¾åƒç”Ÿæˆå·¥å…·åˆ›å»ºé¢„è§ˆå›¾

**æµ‹è¯•å‘½ä»¤**ï¼š
```bash
pdftoppm -h  # å¦‚æœæŠ¥é”™è¯´æ˜ poppler æœªå®‰è£…
```

---

### 2. **Resume-Matcher ATS éªŒè¯æ–¹æ³•**ï¼ˆå‚è€ƒå¼€æºé¡¹ç›®ï¼‰â­

**èƒŒæ™¯**ï¼šä½ æåˆ°å‚è€ƒ [Resume-Matcher](https://github.com/srbhr/Resume-Matcher) ä»“åº“ï¼ˆApache-2.0 licenseï¼Œä¸ä½ çš„ AGPL-3.0 å…¼å®¹ï¼‰ã€‚

**Resume-Matcher çš„ ATS æ–¹æ³•**ï¼š
- ä»–ä»¬ä½¿ç”¨ **NLP + å…³é”®è¯åŒ¹é…**ï¼ˆä¸æ˜¯åœ¨çº¿ ATS å·¥å…·æµ‹è¯•ï¼‰
- æŠ€æœ¯æ ˆï¼šspaCy, word embeddings, text similarity
- æ ¸å¿ƒé€»è¾‘ï¼š
  1. æå– Job Description å…³é”®è¯
  2. æå– Resume å…³é”®è¯
  3. è®¡ç®—ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆcosine similarityï¼‰
  4. ç»™å‡ºåŒ¹é…ç‡å’Œæ”¹è¿›å»ºè®®

**å»ºè®®é›†æˆåˆ°ä½ çš„é¡¹ç›®**ï¼š
```python
# modules/ats_scorer.py (NEW)
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import spacy

class ATSScorer:
    """ATS compatibility scorer inspired by Resume-Matcher"""
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        self.vectorizer = TfidfVectorizer()
    
    def score_resume(self, resume_text: str, job_description: str) -> Dict:
        """Calculate ATS match score"""
        # Vectorize texts
        vectors = self.vectorizer.fit_transform([resume_text, job_description])
        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]
        
        # Extract missing keywords
        jd_keywords = self._extract_keywords(job_description)
        resume_keywords = self._extract_keywords(resume_text)
        missing = set(jd_keywords) - set(resume_keywords)
        
        return {
            "score": int(similarity * 100),  # 0-100
            "missing_keywords": list(missing)[:10],  # Top 10
            "suggestions": self._generate_suggestions(missing)
        }
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extract important keywords using spaCy"""
        doc = self.nlp(text)
        # Extract nouns, proper nouns, and skills
        keywords = [token.text.lower() for token in doc 
                   if token.pos_ in ["NOUN", "PROPN"] and not token.is_stop]
        return keywords
```

**å®æ–½å»ºè®®**ï¼š
- **Phase 2**ï¼šå®ç° `ATSScorer` ç±»
- **Phase 3**ï¼šåœ¨ Resume Export UI æ·»åŠ  "ATS Score" æ˜¾ç¤º
- **Phase 4**ï¼šç”¨ Resume-Matcher çš„æµ‹è¯•æ•°æ®éªŒè¯å‡†ç¡®æ€§

**è‡´è°¢æ–¹å¼**ï¼ˆéµå®ˆ Apache-2.0ï¼‰ï¼š
- åœ¨ README.md çš„ Acknowledgments éƒ¨åˆ†æ·»åŠ ï¼š
  ```markdown
  ## Acknowledgments
  
  - [Resume-Matcher](https://github.com/srbhr/Resume-Matcher) - Inspired our ATS scoring algorithm (Apache-2.0 License)
  ```
- åœ¨ä»£ç æ³¨é‡Šä¸­æ ‡æ³¨ï¼š
  ```python
  # ATS scoring algorithm inspired by Resume-Matcher
  # https://github.com/srbhr/Resume-Matcher (Apache-2.0)
  ```

---

**ğŸ’° ATS Score å•†ä¸šåŒ–å»ºè®®**ï¼ˆå›ç­”ä½ çš„æ”¶è´¹é—®é¢˜ï¼‰

**é—®é¢˜**ï¼šå¾ˆå¤š ATS è½¯ä»¶éƒ½æ”¶è´¹ï¼Œæˆ‘ä»¬çš„ ATS Score è¦ä¸è¦æ”¶è´¹ï¼Ÿ

**å¼€æºé¡¹ç›®çš„å•†ä¸šåŒ–ç­–ç•¥**ï¼ˆAGPL-3.0 å…¼å®¹ï¼‰ï¼š

æˆ‘ç»™ä½  3 ç§é€‰æ‹©ï¼Œä»å®Œå…¨å…è´¹åˆ°éƒ¨åˆ†æ”¶è´¹ï¼š

#### **é€‰é¡¹ 1ï¼šå®Œå…¨å…è´¹**ï¼ˆæ¨èï¼Œé€‚åˆåˆæœŸï¼‰ âœ…

**ç­–ç•¥**ï¼š
- ATS Score åŠŸèƒ½å®Œå…¨å¼€æºå…è´¹
- å¸å¼•ç”¨æˆ·å’Œè´¡çŒ®è€…
- å»ºç«‹å“ç‰Œå’Œç¤¾åŒº

**ä¼˜ç‚¹**ï¼š
- ç¬¦åˆ AGPL-3.0 ç²¾ç¥ï¼ˆå®Œå…¨å¼€æºï¼‰
- å¿«é€Ÿç§¯ç´¯ç”¨æˆ·ï¼ˆGitHub stars, ç¤¾åŒºå£ç¢‘ï¼‰
- ä¸æ¶‰åŠæ”¯ä»˜ç³»ç»Ÿï¼Œç®€åŒ–å¼€å‘

**ç¼ºç‚¹**ï¼š
- æ— æ³•ç›´æ¥å˜ç°
- API æˆæœ¬éœ€è¦è‡ªå·±æ‰¿æ‹…ï¼ˆOpenAI, Apifyï¼‰

**é€‚åˆåœºæ™¯**ï¼š
- ä½ å½“å‰é˜¶æ®µï¼ˆMVPï¼Œç§¯ç´¯ç”¨æˆ·ï¼‰
- æ”¾åœ¨ GitHub å±•ç¤ºç»™é›‡ä¸»ï¼ˆè¯æ˜æŠ€æœ¯èƒ½åŠ›ï¼‰

---

#### **é€‰é¡¹ 2ï¼šFreemium æ¨¡å¼**ï¼ˆå¹³è¡¡æ–¹æ¡ˆï¼‰ âš–ï¸

**ç­–ç•¥**ï¼š
- **åŸºç¡€ç‰ˆå…è´¹**ï¼šæ¯å¤© 5 æ¬¡ ATS Scoreï¼ˆå¼€æºï¼‰
- **é«˜çº§ç‰ˆæ”¶è´¹**ï¼šæ— é™æ¬¡æ•° + è¯¦ç»†åˆ†æï¼ˆé—­æºæ‰©å±•ï¼‰

**æŠ€æœ¯å®ç°**ï¼š
```python
# modules/ats_scorer.py (å¼€æº)
class ATSScorer:
    def score_resume(self, resume_text, job_description):
        # Check usage limit
        if not self._check_quota():
            raise QuotaExceededError("Free tier: 5 scores/day. Upgrade for unlimited.")
        
        # Basic scoring (open source)
        score = self._calculate_basic_score(...)
        return {"score": score, "missing_keywords": [...]}

# modules/ats_scorer_pro.py (é—­æºï¼Œä»…ä»˜è´¹ç”¨æˆ·)
class ATSScorerPro(ATSScorer):
    def score_resume_advanced(self, ...):
        # Advanced features:
        # - Detailed section-by-section analysis
        # - ATS simulation (multiple ATS systems)
        # - Historical score tracking
        return {"score": ..., "detailed_feedback": ...}
```

**AGPL-3.0 åˆè§„æ€§**ï¼š
- âœ… æ ¸å¿ƒç®—æ³•å¼€æºï¼ˆå…è´¹ç‰ˆï¼‰
- âœ… é«˜çº§åŠŸèƒ½å¯ä»¥é—­æºï¼ˆç‹¬ç«‹æ¨¡å—ï¼Œä¸ä¿®æ”¹å¼€æºéƒ¨åˆ†ï¼‰
- âœ… ç”¨æˆ·å¯ä»¥è‡ªå·± host å…è´¹ç‰ˆï¼Œæ— é™åˆ¶ä½¿ç”¨

**é€‚åˆåœºæ™¯**ï¼š
- æƒ³è¦è½»åº¦å˜ç°ï¼Œä½†ä¿ç•™å¼€æºé¡¹ç›®
- å¸å¼•ä¼ä¸šç”¨æˆ·ï¼ˆä»–ä»¬æ„¿æ„ä»˜è´¹ï¼‰

---

#### **é€‰é¡¹ 3ï¼šå®Œå…¨æ”¶è´¹**ï¼ˆéœ€è¦æ”¹ Licenseï¼‰ âŒ

**ç­–ç•¥**ï¼š
- ATS Score åŠŸèƒ½å®Œå…¨æ”¶è´¹
- éœ€è¦å°†é¡¹ç›®æ”¹ä¸º MIT/BSD licenseï¼ˆæ”¾å¼ƒ AGPL-3.0ï¼‰

**é—®é¢˜**ï¼š
- âŒ è¿èƒŒ AGPL-3.0 ç²¾ç¥
- âŒ å¦‚æœä»£ç å·²ç»åœ¨ GitHubï¼Œç”¨æˆ·å¯ä»¥ fork å…è´¹ç‰ˆ
- âŒ Resume-Matcher æ˜¯ Apache-2.0ï¼Œä½ å¿…é¡»å¼€æºä½ çš„ä¿®æ”¹

**ä¸æ¨è**ï¼šä¸ä½ çš„å¼€æºç›®æ ‡å†²çª

---

**æˆ‘çš„å»ºè®®ï¼ˆç»¼åˆè€ƒè™‘ï¼‰**ï¼š

**çŸ­æœŸï¼ˆç°åœ¨-6ä¸ªæœˆï¼‰**ï¼š**é€‰é¡¹ 1 - å®Œå…¨å…è´¹** âœ…
- ç›®æ ‡ï¼šç§¯ç´¯ç”¨æˆ·ã€GitHub starsã€æ±‚èŒå±•ç¤º
- ATS Score å®Œå…¨å¼€æºå…è´¹
- ä¸“æ³¨äº§å“æ‰“ç£¨ï¼Œä¸è€ƒè™‘æ”¶è´¹

**ä¸­æœŸï¼ˆ6ä¸ªæœˆåï¼Œå¦‚æœç”¨æˆ·å¤šï¼‰**ï¼š**é€‰é¡¹ 2 - Freemium** âš–ï¸
- å…è´¹ç‰ˆï¼š5æ¬¡/å¤©ï¼ˆæ»¡è¶³ä¸ªäººç”¨æˆ·ï¼‰
- ä»˜è´¹ç‰ˆï¼š$9.99/æœˆï¼Œæ— é™æ¬¡ + é«˜çº§åˆ†æ
- æ”¶å…¥è¦†ç›– API æˆæœ¬

**é•¿æœŸï¼ˆ1å¹´åï¼Œå¦‚æœå•†ä¸šåŒ–ï¼‰**ï¼š
- ä¼ä¸šç‰ˆï¼š$49/æœˆï¼Œå›¢é˜ŸåŠŸèƒ½ï¼ˆHR æ‰¹é‡åˆ†æç®€å†ï¼‰
- API æ¥å…¥ï¼šæŒ‰è°ƒç”¨æ¬¡æ•°æ”¶è´¹

---

**æ³•å¾‹åˆè§„æ€§**ï¼ˆAGPL-3.0 + Apache-2.0ï¼‰ï¼š

**ä½ çš„æ‹…å¿ƒï¼š"æœ‰äº† GPL-3 å’Œ Apache-2 åè®®ï¼Œé¡¹ç›®ä¼šä¸ä¼šè¢«å°ï¼Ÿ"**

âœ… **å®Œå…¨ä¸ä¼šè¢«å°ï¼åè€Œæ›´å®‰å…¨ï¼** 

**ä¸ºä»€ä¹ˆï¼Ÿ**

1. **AGPL-3.0 æ˜¯åˆæ³•çš„å¼€æºåè®®**
   - å…¨çƒæ•°åƒä¸ªé¡¹ç›®ä½¿ç”¨ï¼ˆå¦‚ MongoDB, Grafanaï¼‰
   - GitHub å®˜æ–¹æ”¯æŒ
   - æ²¡æœ‰ä»»ä½•æ³•å¾‹é£é™©

2. **Apache-2.0 å…¼å®¹ AGPL-3.0**
   - Apache-2.0 æ›´å®½æ¾ï¼Œå¯ä»¥é›†æˆåˆ° AGPL-3.0
   - Resume-Matcher å…è®¸ä½ ä½¿ç”¨ä»–ä»¬çš„ä»£ç ï¼ˆåªéœ€è‡´è°¢ï¼‰
   - ä½ çš„é¡¹ç›®ä¸ä¼šä¾µæƒ

3. **"è¢«å°"çš„å”¯ä¸€å¯èƒ½**ï¼ˆä½†ä½ ä¸ä¼šé‡åˆ°ï¼‰
   - âŒ æŠ„è¢­é—­æºå•†ä¸šè½¯ä»¶ä»£ç ï¼ˆå¦‚ Grammarlyï¼‰
   - âŒ è¿å API æœåŠ¡æ¡æ¬¾ï¼ˆå¦‚çˆ¬è™«è¢«å°ï¼‰
   - âŒ ç›—ç”¨ä»–äººç§æœ‰ä»£ç 
   
   **ä½ çš„æƒ…å†µ**ï¼š
   - âœ… ä½¿ç”¨å¼€æºé¡¹ç›®ï¼ˆResume-Matcher, Apache-2.0ï¼‰
   - âœ… æ­£ç¡®è‡´è°¢
   - âœ… éµå®ˆ AGPL-3.0
   - âœ… è°ƒç”¨åˆæ³• APIï¼ˆOpenAI, Apifyï¼‰

**ç»“è®º**ï¼šä½ çš„é¡¹ç›® 100% å®‰å…¨ï¼Œä¸ä¼šè¢«å°ï¼ ğŸ‰

**å”¯ä¸€æ³¨æ„äº‹é¡¹**ï¼š
- å¦‚æœæœªæ¥å•†ä¸šåŒ–ï¼ŒAGPL-3.0 è¦æ±‚ï¼š
  - æ‰€æœ‰ä¿®æ”¹å¿…é¡»å¼€æº
  - æä¾› SaaS æœåŠ¡ä¹Ÿè¦å¼€æºä»£ç 
- å¦‚æœæƒ³é—­æºï¼Œéœ€è¦æ”¹æˆ MIT licenseï¼ˆä½†å·²å‘å¸ƒçš„ç‰ˆæœ¬æ°¸è¿œæ˜¯ AGPL-3.0ï¼‰

---

### 3. **1é¡µçº¦æŸçš„æŒ‘æˆ˜**ï¼ˆä¸åŒæ¨¡æ¿é™åˆ¶ä¸åŒï¼‰

**é—®é¢˜**ï¼š
- **Two-column æ¨¡æ¿** å¯ä»¥å®¹çº³æ›´å¤šå†…å®¹ï¼ˆ~700 wordsï¼‰
- **Single-column æ¨¡æ¿** åªèƒ½å®¹çº³ ~600 words
- ä½ çš„ AI å‹ç¼©å¦‚æœç»Ÿä¸€ç”¨ 600 wordsï¼Œå¯èƒ½ä¼šåœ¨ two-column æ¨¡æ¿ä¸Šæµªè´¹ç©ºé—´

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
def compress_to_one_page(self, resume_data: Dict, template: Dict, job_description: str):
    # Calculate word limit based on template
    if template.get('layout') == 'two_column':
        word_limit = 700
    else:
        word_limit = 600
    
    # Adjust line spacing
    line_spacing = template.get('line_spacing', 1.0)
    if line_spacing < 1.0:
        word_limit += 50  # Tighter spacing allows more words
```

**å»ºè®®**ï¼šPhase 2 å®ç°æ—¶ï¼Œæ ¹æ®æ¨¡æ¿åŠ¨æ€è°ƒæ•´ word limitã€‚

---

### 4. **ATS å…¼å®¹æ€§éªŒè¯**ï¼ˆå¦‚ä½•æµ‹è¯•ï¼Ÿï¼‰

> [!NOTE]
> **æ¾„æ¸…ç¬¬3ç‚¹å’Œç¬¬4ç‚¹çš„å…³ç³»**ï¼ˆå›ç­”ä½ çš„å›°æƒ‘ï¼‰
> 
> ä½ æåˆ°ï¼š"åŒæ—¶æœ‰3å’Œ4ä¸¤ç‚¹æˆ‘æœ‰ç‚¹æ‡µ"ï¼Œè®©æˆ‘è§£é‡Šæ¸…æ¥šï¼š
> 
> - **ç¬¬ 2 ç‚¹ï¼ˆResume-Matcher ATS éªŒè¯ï¼‰**ï¼šè¿™æ˜¯æˆ‘ä»¬**è‡ªå·±å®ç°**çš„ ATS Score ç®—æ³•
>   - ç”¨ NLP + å…³é”®è¯åŒ¹é…
>   - ä»£ç åœ¨ `modules/ats_scorer.py`
>   - ç»™ç®€å†æ‰“åˆ†ï¼ˆ0-100ï¼‰
>   - ç”¨æˆ·åœ¨ UI çœ‹åˆ° "ATS Score: 85/100"
> 
> - **ç¬¬ 4 ç‚¹ï¼ˆATS å…¼å®¹æ€§éªŒè¯ï¼‰**ï¼šè¿™æ˜¯**æµ‹è¯•æˆ‘ä»¬çš„æ¨¡æ¿**æ˜¯å¦çœŸçš„ ATS-friendly
>   - ç›®çš„ï¼šéªŒè¯æˆ‘ä»¬çš„ 4 ä¸ªç®€å†æ¨¡æ¿èƒ½å¦è¢«çœŸå® ATS ç³»ç»Ÿæ­£ç¡®è§£æ
>   - æ–¹æ³•ï¼šç”¨åœ¨çº¿ ATS å·¥å…·ï¼ˆJobscan, Resume Wordedï¼‰æµ‹è¯•
>   - ä¸æ˜¯ç»™ç”¨æˆ·ç”¨çš„ï¼Œæ˜¯**æˆ‘ä»¬å¼€å‘è€…è‡ªå·±æµ‹è¯•**
> 
> **ç®€å•è¯´**ï¼š
> - **ç¬¬ 2 ç‚¹**ï¼šæˆ‘ä»¬åšçš„ ATS Score åŠŸèƒ½ï¼ˆç»™ç”¨æˆ·ç”¨ï¼‰
> - **ç¬¬ 4 ç‚¹**ï¼šæµ‹è¯•æˆ‘ä»¬çš„æ¨¡æ¿è´¨é‡ï¼ˆæˆ‘ä»¬è‡ªå·±éªŒè¯ï¼‰
> 
> **ä¸¤è€…å…³ç³»**ï¼š
> - ç¬¬ 2 ç‚¹æ˜¯**åŠŸèƒ½**ï¼ˆäº§å“çš„ä¸€éƒ¨åˆ†ï¼‰
> - ç¬¬ 4 ç‚¹æ˜¯**æµ‹è¯•**ï¼ˆç¡®ä¿äº§å“è´¨é‡ï¼‰
> 
> **å®æ–½æ—¶é—´**ï¼š
> - ç¬¬ 2 ç‚¹ï¼šPhase 2-3ï¼ˆå®ç° + é›†æˆåˆ° UIï¼‰
> - ç¬¬ 4 ç‚¹ï¼šPhase 4ï¼ˆæµ‹è¯•é˜¶æ®µï¼Œç”¨çœŸå®å·¥å…·éªŒè¯ï¼‰

**é—®é¢˜**ï¼šä½ è¯´æ¨¡æ¿æ˜¯ "ATS-friendly"ï¼Œä½†æ€ä¹ˆéªŒè¯ï¼Ÿ

**å»ºè®®çš„æµ‹è¯•æ–¹æ³•**ï¼š
1. **ä½¿ç”¨åœ¨çº¿ ATS æ‰«æå·¥å…·**ï¼š
   - Jobscan.coï¼ˆå…è´¹ç‰ˆæ¯æœˆ 5 æ¬¡ï¼‰
   - Resume Wordedï¼ˆå…è´¹ç‰ˆï¼‰
   - TopResume ATS checker
   
2. **æµ‹è¯•æµç¨‹**ï¼š
   - ç”¨æ¯ä¸ªæ¨¡æ¿å¯¼å‡ºç®€å†
   - ä¸Šä¼ åˆ° ATS å·¥å…·
   - æ£€æŸ¥è§£æå‡†ç¡®ç‡ï¼ˆ>90% æ‰ç®—åˆæ ¼ï¼‰
   
3. **å¸¸è§ ATS é—®é¢˜**ï¼š
   - Two-column æ¨¡æ¿å¯èƒ½è¢«æŸäº›è€æ—§ ATS è¯¯è§£æï¼ˆå·¦å³åˆ—æ··ä¹±ï¼‰
   - è¡¨æ ¼ä¼šå¯¼è‡´è§£æå¤±è´¥
   - éæ ‡å‡† section æ ‡é¢˜ï¼ˆå¦‚ "Professional Background" vs "Experience"ï¼‰

**å»ºè®®**ï¼šPhase 4 Testing é˜¶æ®µï¼Œç”¨çœŸå® ATS å·¥å…·éªŒè¯æ‰€æœ‰æ¨¡æ¿ã€‚

---

### 5. **AI è°ƒç”¨å»¶è¿Ÿ**ï¼ˆç”¨æˆ·ä½“éªŒé—®é¢˜ï¼‰

**é—®é¢˜**ï¼š
- `tailor_resume()` è°ƒç”¨ GPT-4o-mini éœ€è¦ 2-5 ç§’
- `compress_to_one_page()` ç”Ÿæˆ 3 ä¸ªç‰ˆæœ¬éœ€è¦ 6-15 ç§’
- ç”¨æˆ·ç‚¹å‡» "Export" åéœ€è¦ç­‰å¾…ï¼Œæ²¡æœ‰è¿›åº¦æç¤º

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# In streamlit_app.py
with st.spinner("ğŸ¤– AI is tailoring your resume... (5-10 seconds)"):
    tailored = resume_generator.tailor_resume(...)

# Add progress bar
import time
progress_bar = st.progress(0)
for i in range(3):
    # Generate version i
    progress_bar.progress((i+1) / 3)
    time.sleep(0.1)
```

**å»ºè®®**ï¼šPhase 3 Frontend å®ç°æ—¶ï¼Œæ·»åŠ å‹å¥½çš„ loading æç¤ºã€‚

---

### 6. **æ¨¡æ¿é¢„è§ˆå›¾è´¨é‡**ï¼ˆ300x400 å¯èƒ½å¤ªå°ï¼‰

**é—®é¢˜**ï¼š
- 300x400px åœ¨é«˜åˆ†è¾¨ç‡å±å¹•ä¸Šå¯èƒ½æ¨¡ç³Š
- ç”¨æˆ·æ— æ³•çœ‹æ¸…æ¨¡æ¿ç»†èŠ‚ï¼ˆå­—ä½“å¤§å°ã€è¡Œé—´è·ç­‰ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç”Ÿæˆ 600x800px é¢„è§ˆå›¾ï¼ˆ2xï¼‰ï¼ŒStreamlit ä¼šè‡ªåŠ¨ç¼©æ”¾
- æ·»åŠ  "ç‚¹å‡»æ”¾å¤§" åŠŸèƒ½ï¼ˆ`st.image` æ”¯æŒ lightboxï¼‰

**ä»£ç ç¤ºä¾‹**ï¼š
```python
st.image(f"assets/templates/{template}.jpg", 
         use_container_width=True,
         caption="Click to enlarge")  # Streamlit è‡ªåŠ¨æ”¯æŒç‚¹å‡»æ”¾å¤§
```

**å»ºè®®**ï¼šPhase 1 ç”Ÿæˆé¢„è§ˆå›¾æ—¶ï¼Œç”¨ 600x800pxã€‚

---

### 7. **ç‰ˆæœ¬å†å²å­˜å‚¨ç©ºé—´**ï¼ˆæ•°æ®åº“è†¨èƒ€ï¼‰

**é—®é¢˜**ï¼š
- æ¯æ¬¡å¯¼å‡ºä¿å­˜å®Œæ•´çš„ resume JSONï¼ˆ~2KBï¼‰
- å¦‚æœç”¨æˆ·å¯¼å‡º 100 æ¬¡ï¼Œå°±æ˜¯ 200KB
- å¦‚æœæœ‰ 1000 ä¸ªç”¨æˆ·ï¼Œå°±æ˜¯ 200MBï¼ˆä¸ç®— DOCX/PDF æ–‡ä»¶ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **çŸ­æœŸ**ï¼šæ— éœ€ä¼˜åŒ–ï¼ŒSQLite å¯ä»¥è½»æ¾å¤„ç† GB çº§æ•°æ®
- **é•¿æœŸ**ï¼šå¦‚æœå•†ä¸šåŒ–ï¼Œè€ƒè™‘ï¼š
  - åªä¿ç•™æœ€è¿‘ 10 ä¸ªç‰ˆæœ¬
  - å°† DOCX/PDF ä¸Šä¼ åˆ°äº‘å­˜å‚¨ï¼ˆAWS S3ï¼‰
  - å®ç° "Diff" å­˜å‚¨ï¼ˆåªå­˜æ”¹åŠ¨éƒ¨åˆ†ï¼‰

**å»ºè®®**ï¼šå½“å‰é˜¶æ®µä¸ç”¨ç®¡ï¼ŒMVP ä¸éœ€è¦ä¼˜åŒ–å­˜å‚¨ã€‚

---

### 8. **DOCX vs PDF é€‰æ‹©å»ºè®®**ï¼ˆç”¨æˆ·å›°æƒ‘ï¼‰

**é—®é¢˜**ï¼šç”¨æˆ·ç‚¹å‡» "Export" æ—¶ï¼Œçœ‹åˆ° DOCX å’Œ PDF ä¸¤ä¸ªæŒ‰é’®ï¼Œä¸çŸ¥é“é€‰å“ªä¸ªã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
st.info("""
ğŸ“¥ **Export Format Guide:**
- **DOCX**: Choose this if you need to edit the resume later (ATS-friendly)
- **PDF**: Choose this for final submission (looks more professional, but not editable)
- **Recommendation**: Export both! Use DOCX for ATS systems, PDF for email attachments.
""")
```

**å»ºè®®**ï¼šPhase 3 Frontend æ·»åŠ æ­¤æç¤ºã€‚

---

### 9. **Section Reordering çš„è¾¹ç•Œæƒ…å†µ**

**é—®é¢˜**ï¼š
- å¦‚æœç”¨æˆ·ç§»é™¤äº† "Experience" sectionï¼Œç®€å†è¿˜æœ‰æ•ˆå—ï¼Ÿ
- å¦‚æœç”¨æˆ·æŠŠ "Contact" ç§»åˆ°æœ€åï¼ŒATS ä¼šè§£æå¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# Validate section order
required_sections = ["header", "contact", "experience"]
for section in required_sections:
    if section not in reordered_sections:
        st.error(f"âš ï¸ Required section '{section}' cannot be removed!")
        return

# Warn if contact is not in top 2
if reordered_sections.index("contact") > 1:
    st.warning("âš ï¸ ATS may fail to parse contact info if not near the top")
```

**å»ºè®®**ï¼šPhase 3 Frontend æ·»åŠ éªŒè¯é€»è¾‘ã€‚

---

### 10. **Master Resume æ ¼å¼æ£€æµ‹**ï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰

**é—®é¢˜**ï¼šç”¨æˆ·ä¸Šä¼ æ–‡ä»¶åï¼Œä½ æ€ä¹ˆçŸ¥é“æ˜¯ MD/PDF/DOCXï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# In streamlit_app.py
uploaded_file = st.file_uploader("Upload Master Resume", 
                                 type=["md", "pdf", "docx"])

if uploaded_file:
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    if file_ext == "md":
        master_resume = resume_generator.load_master_resume(uploaded_file)
    elif file_ext == "pdf":
        master_resume = resume_generator.parse_pdf_resume(uploaded_file)
    elif file_ext == "docx":
        master_resume = resume_generator.parse_docx_resume(uploaded_file)
```

**å»ºè®®**ï¼šPhase 3 Frontend å·²ç»åŒ…å«æ­¤é€»è¾‘ï¼ˆfile_uploader çš„ `type` å‚æ•°ï¼‰ã€‚

---

## ğŸ“ è¡¥å……çš„ Success Criteria

åŸºäºä»¥ä¸Šé—®é¢˜ï¼Œæˆ‘å»ºè®®åœ¨åŸæœ‰çš„ Success Criteria åŸºç¡€ä¸Šï¼Œå†æ·»åŠ ï¼š

- [ ] **Poppler æˆåŠŸå®‰è£…**ï¼ˆWindows æµ‹è¯•ï¼‰
- [ ] **é¢„è§ˆå›¾æ¸…æ™°å¯è§**ï¼ˆ600x800pxï¼Œé 300x400ï¼‰
- [ ] **ATS å·¥å…·éªŒè¯é€šè¿‡**ï¼ˆJobscan è¯„åˆ† >90%ï¼‰
- [ ] **AI è°ƒç”¨æœ‰ Loading æç¤º**ï¼ˆä¸è®©ç”¨æˆ·ç­‰å¾…æ—¶ç„¦è™‘ï¼‰
- [ ] **DOCX/PDF é€‰æ‹©æœ‰æŒ‡å¯¼**ï¼ˆç”¨æˆ·çŸ¥é“è¯¥ä¸‹è½½å“ªä¸ªï¼‰
- [ ] **Section Reordering æœ‰éªŒè¯**ï¼ˆé˜²æ­¢ç”¨æˆ·åˆ é™¤å¿…éœ€ sectionsï¼‰

---

## ğŸš€ Next Steps

å®Œæˆæœ¬æ¬¡å®æ–½å,é¡¹ç›®å°†å…·å¤‡å®Œæ•´çš„ Resume Export åŠŸèƒ½ã€‚åç»­å¯ä»¥ä¼˜åŒ–çš„æ–¹å‘ï¼š

1. **æ¨¡æ¿æ‰©å±•**ï¼šå¢åŠ æ›´å¤šæ¨¡æ¿ï¼ˆAcademic, Creative, Executiveï¼‰
2. **å®æ—¶é¢„è§ˆ**ï¼šåœ¨ UI ä¸­å®æ—¶æ¸²æŸ“ç®€å†é¢„è§ˆï¼ˆç›®å‰åªæœ‰ word countï¼‰
3. **ATS Score**ï¼šé›†æˆ ATS scan å·¥å…·è¯„ä¼°ç®€å†é€šè¿‡ç‡
4. **Batch Export**ï¼šä¸€é”®ä¸ºå¤šä¸ªèŒä½ç”Ÿæˆå®šåˆ¶ç®€å†
5. **ä¸­æ–‡æ”¯æŒ**ï¼šæ·»åŠ ä¸­æ–‡å­—ä½“ï¼Œæ”¯æŒåŒè¯­ç®€å†

---

**é¢„è®¡æ€»å·¥æ—¶**ï¼š5 å°æ—¶ï¼ˆåŸ 4 å°æ—¶ + 1 å°æ—¶ UI ä¼˜åŒ–ï¼‰  
**æ–‡ä»¶å˜æ›´**ï¼š18 ä¸ªæ–‡ä»¶
- **æ–°å¢ 11 ä¸ª**ï¼š
  - 4 ä¸ª template JSON
  - 4 å¼  template preview JPG
  - `generate_template_previews.py`
  - `ats_scorer.py`ï¼ˆResume-Matcher inspiredï¼‰
  - `test_dependencies.py`
- **ä¿®æ”¹ 7 ä¸ª**ï¼š
  - `streamlit_app.py`ï¼ˆæ–°å¢ Resume Export é¡µé¢ + UI ç¾åŒ–ï¼‰
  - `resume_generator.py`ï¼ˆæ¨¡æ¿ç³»ç»Ÿ + PDF/DOCX è§£æï¼‰
  - `database.py`ï¼ˆSchema å˜æ›´ï¼‰
  - `requirements.txt`ï¼ˆ+8 ä¸ªæ–°ä¾èµ–ï¼‰
  - `scripts/init_database.py`ï¼ˆmigrationï¼‰
  - `README.md`ï¼ˆè‡´è°¢ Resume-Matcher + License è¯´æ˜ï¼‰
  
**é£é™©ç­‰çº§**ï¼šä¸­ç­‰ï¼ˆä¸»è¦é£é™©åœ¨ poppler å®‰è£…ï¼Œå…¶ä»–éƒ½å¯æ§ï¼‰  
**å¼€æºåè®®**ï¼šAGPL-3.0ï¼ˆå…¼å®¹ Apache-2.0 çš„ Resume-Matcherï¼‰

å‡†å¤‡å¥½å¼€å§‹å®æ–½äº†å—ï¼ŸğŸš€
